{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://wikidocs.net/52460"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "# 텐서 조작하기 1\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# numpy로 1차원 벡터 만들기\r\n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 벡터의 차원과 크기를 출력\r\n",
    "# 차원\r\n",
    "print('Rank of t:', t.ndim)\r\n",
    "# 크기\r\n",
    "print('shape of t:', t.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rank of t: 1\n",
      "shape of t: (7,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 너무 기초라서 조금 생략"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3. 파이토치 텐서 선언하기"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 1D with pytorch\r\n",
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.,])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 텐서의 차원\r\n",
    "print(t.dim())\r\n",
    "\r\n",
    "# 텐서의 크기\r\n",
    "print(t.shape)\r\n",
    "print(t.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(t[0], t[1], t[-1])  # 인덱스로 접근\r\n",
    "print(t[2:5], t[4:-1])    # 슬라이싱\r\n",
    "print(t[:2], t[3:])       # 슬라이싱"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 2D with Pytorch\r\n",
    "\r\n",
    "t = torch.FloatTensor([[1., 2., 3.],\r\n",
    "                       [4., 5., 6.],\r\n",
    "                       [7., 8., 9.],\r\n",
    "                       [10., 11., 12.]\r\n",
    "                      ])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 텐서의 차원\r\n",
    "print(t.dim())\r\n",
    "\r\n",
    "# 텐서의 크기\r\n",
    "print(t.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3) 브로드캐스팅\r\n",
    "# 크기가 다른 텐서에 대해 사칙 연산을 수행 할 때 브로드캐스팅 이라는 기능을 이용 할 수 있다."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 우선 크기가 같을 때\r\n",
    "m1 = torch.FloatTensor([[3,3]])\r\n",
    "m2 = torch.FloatTensor([[2,2]])\r\n",
    "print(m1 + m2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 크기가 다를 때\r\n",
    "# Vector + scalar\r\n",
    "m1 = torch.FloatTensor([[1,2]])\r\n",
    "m2 = torch.FloatTensor([3])\r\n",
    "print(m1+m2)\r\n",
    "\r\n",
    "# m2 인 [3] 에 브로드캐스팅이 적용 되어 [3,3]로 바꿔 연산 된다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 2*1 Vector + 1*2 Vector\r\n",
    "m1 = torch.FloatTensor([[1,2]])\r\n",
    "m2 = torch.FloatTensor([[3],[4]])\r\n",
    "print(m1 + m2)\r\n",
    "\r\n",
    "# m2 : [[3], [4]] >> [[3,3], [4,4]]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 4) 자주 사용되는 기능들"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 행렬곱과 그냥 곱셈의 차이\r\n",
    "# 행렬곱 : .matmul\r\n",
    "# 원소 별 곱셈 : .mul"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "m1 = torch.FloatTensor([[1,2], [3,4]])\r\n",
    "m2 = torch.FloatTensor([[1], [2]])\r\n",
    "\r\n",
    "print('shape of matrix 1: ', m1.shape)\r\n",
    "print('shape of matrix 2: ', m2.shape)\r\n",
    "print(m1.matmul(m2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of matrix 1:  torch.Size([2, 2])\n",
      "shape of matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "m1 = torch.FloatTensor([[1,2], [3,4]])\r\n",
    "m2 = torch.FloatTensor([[1], [2]])\r\n",
    "\r\n",
    "print('shape of matrix 1: ', m1.shape)\r\n",
    "print('shape of matrix 2: ', m2.shape)\r\n",
    "print(m1 * m2)\r\n",
    "print(m1.mul(m2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of matrix 1:  torch.Size([2, 2])\n",
      "shape of matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 평균 구하기"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 1차원 평균\r\n",
    "t = torch.FloatTensor([1, 2])\r\n",
    "print(t.mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 2차원 평균\r\n",
    "t = torch.FloatTensor([[1, 2], \r\n",
    "                       [3, 4]])\r\n",
    "print(t)\r\n",
    "\r\n",
    "# 4개의 원소에 대한 평균을 반환\r\n",
    "print(t.mean())\r\n",
    "# 차원을 인자로 줄 경우 (dim=0 , 행을 제거하고 열만 고려)\r\n",
    "print(t.mean(dim=0))    # 1,3 의 평균과 2,4 평균을 반환\r\n",
    "# 차원을 인자로 줄 경우 (dim=1, 열을 제거하고 행만 고려)\r\n",
    "print(t.mean(dim=1))    # 1,2 의 평균과 3,4 평균을 반환\r\n",
    "# 차원을 인자로 줄 경우 (dim=-1 , 마지막 차원을 제거 == 열을 제거)\r\n",
    "print(t.mean(dim=-1))    # 1,2 의 평균과 3,4 평균을 반환"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 덧셈"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(t.sum()) # 단순히 원소 전체의 덧셈을 수행\r\n",
    "print(t.sum(dim=0)) # 행을 제거\r\n",
    "print(t.sum(dim=1)) # 열을 제거\r\n",
    "print(t.sum(dim=-1)) # 열을 제거"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 최대와 아그맥스\r\n",
    "# max : 원소의 최대값 반환\r\n",
    "# agmax : 최대값을 가진 인덱스를 리턴"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(t.max())\r\n",
    "print('-'*20)\r\n",
    "print(t.max(dim=0)) # 행을 제거하고 열만 고려만 최대값 반환\r\n",
    "# max에 dim을 인자로 주면 argmax도 함께 반환함"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(4.)\n",
      "--------------------\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# max 또는 argmax만 반환 받고 싶을 때\r\n",
    "print('Max: ', t.max(dim=0)[0])\r\n",
    "print('Argmax: ', t.max(dim=0)[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# dim 인자를 1, -1로 주었을 때\r\n",
    "print(t.max(dim=1))\r\n",
    "print('-'*20)\r\n",
    "print(t.max(dim=-1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "--------------------\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b18ecf447b39d25eae6a9ae9d5694327d58d99c869301a8afbbe0bb2ae2074bb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
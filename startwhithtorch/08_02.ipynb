{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 02. 토치텍스트 튜토리얼(Torchtext tutorial) - 영어\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "파이토치(PyTorch)에서는 텍스트에 대한 여러 추상화 기능을 제공하는 자연어 처리 라이브러리 토치텍스트(Torchtext)를 제공한다.  \r\n",
    "\r\n",
    "**torchtext가 제공하는 기능**  \r\n",
    "1. 파일 로드하기(File Loading) : 다양한 포맷의 코퍼스를 로드합니다.\r\n",
    "2. 토큰화(Tokenization) : 문장을 단어 단위로 분리해줍니다.\r\n",
    "3. 단어 집합(Vocab) : 단어 집합을 만듭니다.\r\n",
    "4. 정수 인코딩(Integer encoding) : 전체 코퍼스의 단어들을 각각의 고유한 정수로 맵핑합니다.\r\n",
    "5. 단어 벡터(Word Vector) : 단어 집합의 단어들에 고유한 임베딩 벡터를 만들어줍니다.  \r\n",
    "   랜덤값으로 초기화한 값일 수도 있고, 사전 훈련된 임베딩 벡터들을 로드할 수도 있습니다.\r\n",
    "6. 배치화(Batching) : 훈련 샘플들의 배치를 만들어줍니다. 이 과정에서 패딩 작업(Padding)도 이루어집니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 훈련 데이터와 테스트 데이터로 분리하기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# IMDB 리뷰 데이터를 다운받고 training/test로 분리하고 csv로 저장하여 사용하자 \r\n",
    "import urllib.request\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x26dd86b9340>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 다운한 데이터를 df에 저장하고 상위 5개만 출력\r\n",
    "df = pd.read_csv('IMDb_Reviews.csv', encoding='latin1')\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 전체 샘플의 개수 확인\r\n",
    "print('전체 샘플 개수: {}'.format(len(df)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "전체 샘플 개수: 50000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 5:5로 분리하여 데이터를 나누자\r\n",
    "train_df = df[:25000]\r\n",
    "test_df = df[25000:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 각각의 데이터셋을 csv로 저장\r\n",
    "train_df.to_csv('train_data.csv', index=False)\r\n",
    "test_df.to_csv('test_data.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 필드 정의하기(torchtext.data)\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# torchtext.data에 field라는 도구를 사용하여 앞으로 어떤 전처리를 할 것인지 정의하자\r\n",
    "from torchtext.legacy import data\r\n",
    "\r\n",
    "# 필드 정의\r\n",
    "# 실제 텍스트를 위한 text 객체\r\n",
    "TEXT = data.Field(sequential = True,      # 시퀀스 여부(default: True)\r\n",
    "                  use_vocab = True,       # 단어 집합을 만들 것인지 여부(default: True)\r\n",
    "                  tokenize = str.split,   # 어떤 토큰화 함수를 사용할 것인지 지정(default: string.split)\r\n",
    "                  lower = True,           # 영어 데이터를 모두 소문자화 한다(default: False)\r\n",
    "                  batch_first = True,     # 미니배치차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부(default: False)\r\n",
    "                                          # True면 tensor의 맨 앞이 batch 차원이 되도록 한다.\r\n",
    "                  fix_length = 20)        # 최대 허용 길이. 이 기준으로 padding이 된다.\r\n",
    "\r\n",
    "# 레이블 데이터를 위한 lable 객체\r\n",
    "LABEL = data.Field(sequential = False,\r\n",
    "                  use_vocab = False,\r\n",
    "                  batch_first = False,\r\n",
    "                  is_target = True)       # 레이블 데이터 여부(defalut: False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 데이터셋 만들기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from torchtext.legacy.data import TabularDataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# field로 토큰화 수행\r\n",
    "train_data, test_data = TabularDataset.splits(\r\n",
    "    path='.',\r\n",
    "    train = 'train_data.csv',\r\n",
    "    test = 'test_data.csv',\r\n",
    "    format = 'csv',\r\n",
    "    fields = [('text', TEXT), ('label', LABEL)], \r\n",
    "    skip_header=True    # 데이터의 첫번째 줄은 무시\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 잘 진행되었는지 확인\r\n",
    "print('훈련 샘플의 개수:{}'.format(len(train_data)))\r\n",
    "print('테스트 샘플의 개수:{}'.format(len(test_data)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "훈련 샘플의 개수:25000\n",
      "테스트 샘플의 개수:25000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# vars()를 이용해 주어진 인텍스의 샘플을 확인 가능\r\n",
    "\r\n",
    "print(vars(train_data[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'text': ['my', 'family', 'and', 'i', 'normally', 'do', 'not', 'watch', 'local', 'movies', 'for', 'the', 'simple', 'reason', 'that', 'they', 'are', 'poorly', 'made,', 'they', 'lack', 'the', 'depth,', 'and', 'just', 'not', 'worth', 'our', 'time.<br', '/><br', '/>the', 'trailer', 'of', '\"nasaan', 'ka', 'man\"', 'caught', 'my', 'attention,', 'my', 'daughter', 'in', \"law's\", 'and', \"daughter's\", 'so', 'we', 'took', 'time', 'out', 'to', 'watch', 'it', 'this', 'afternoon.', 'the', 'movie', 'exceeded', 'our', 'expectations.', 'the', 'cinematography', 'was', 'very', 'good,', 'the', 'story', 'beautiful', 'and', 'the', 'acting', 'awesome.', 'jericho', 'rosales', 'was', 'really', 'very', 'good,', \"so's\", 'claudine', 'barretto.', 'the', 'fact', 'that', 'i', 'despised', 'diether', 'ocampo', 'proves', 'he', 'was', 'effective', 'at', 'his', 'role.', 'i', 'have', 'never', 'been', 'this', 'touched,', 'moved', 'and', 'affected', 'by', 'a', 'local', 'movie', 'before.', 'imagine', 'a', 'cynic', 'like', 'me', 'dabbing', 'my', 'eyes', 'at', 'the', 'end', 'of', 'the', 'movie?', 'congratulations', 'to', 'star', 'cinema!!', 'way', 'to', 'go,', 'jericho', 'and', 'claudine!!'], 'label': '1'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 필드 구성 확인\r\n",
    "print(train_data.fields.items())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_items([('text', <torchtext.legacy.data.field.Field object at 0x0000026E2E918550>), ('label', <torchtext.legacy.data.field.Field object at 0x0000026E2E918B50>)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 단어 집합(Vocabulary) 만들기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# 토큰화 전처리를 끝냈으니\r\n",
    "# 정수 인코딩(interger encoding) 작업을 진행하자\r\n",
    "# 그를 위해선 단어 집합을 먼저 만들어야 한다"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# 정의한 field에 .build_vocab() 도구를 사용하면 vocab을 생성할 수 있다\r\n",
    "TEXT.build_vocab(train_data,        # 해당 데이터\r\n",
    "                 min_freq=10,       # 단어 집합에 추가 시 단어의 최소 등장 빈도 조건\r\n",
    "                 max_size=10000)    # 단어 집합의 최대 크기"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print('단어 집합의 크기: {}'.format(len(TEXT.vocab)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "단어 집합의 크기: 10002\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# 토치텍스트가 임의로 특별 토큰인 <unk>와 <pad>를 추가하였기 때문에 길이가 max_size + 2이다.\r\n",
    "# <unk>의 번호는 0번, <pad>의 번호는 1번을 부여"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 생성된 단어 집합 내의 단어들은 .stoi를 통해서 확인 가능\r\n",
    "print(TEXT.vocab.stoi)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 토치텍스트의 데이터로더 만들기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# DataLoader는 dataset에서 mini batch만큼 데이터를 불러오는 역할을 한다. \r\n",
    "# torchtext 에서는 Iterator를 사용해 DataLoader를 만든다"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from torchtext.legacy.data import Iterator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# 임의로 배치 크기를 아주 작은 5로 지정\r\n",
    "batch_size = 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "train_loader = Iterator(dataset=train_data, batch_size=batch_size)\r\n",
    "test_loader = Iterator(dataset=test_data, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "print('예상 미니 배치 수: {}'.format(25000/5))\r\n",
    "print('훈련 데이터의 미니 배치 수: {}'.format(len(train_loader)))\r\n",
    "print('테스트 데이터의 미니 배치 수: {}'.format(len(test_loader)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "예상 미니 배치 수: 5000.0\n",
      "훈련 데이터의 미니 배치 수: 5000\n",
      "테스트 데이터의 미니 배치 수: 5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 이제 첫번째 미니 배치를 받아와서 batch 라는 변수에 저장해보자\r\n",
    "batch = next(iter(train_loader))    # iter()로 받은 train_loader의 첫번째 미니배치"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print(type(batch))\r\n",
    "# 타입이 tensor가 아님을 확인"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torchtext.legacy.data.batch.Batch'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# 실제 데이터 텐서에 접근하기 위해서는 정의한 필드명이 필요\r\n",
    "\r\n",
    "# 첫번째 미니 배치의 text 필드를 호출해보자\r\n",
    "print(batch.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[   9,   39, 1423,   63,    2,  320, 1012,    5,   10,   20,  136,   19,\n",
      "         3951,    8,    0,  106,   11,   41,   71,  685],\n",
      "        [  10,    7,    2,   77,    5,    3,  239,   35,  358,   63,    6,   66,\n",
      "            3,  274,    4,   11,  567,   47,    6,   28],\n",
      "        [2060,  147,  280,   11,   61,   91,   28,    3, 4543,  440,  440,  440,\n",
      "           44,  658,    5,  116,   36, 3171,   29,    2],\n",
      "        [   3,  167,    5,   89,   83,   98,    0, 5806,   25,    7,   36,   12,\n",
      "          524,   18,    9,  205, 1057,    9,   98,   11],\n",
      "        [   3, 1740,  405,   17,  503,  181,   12,  300,   99, 2998,    2,  650,\n",
      "           40,    2,  228, 4871,   60,  583,   79,  261]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 배치 크기가 5이기 때문에, 5개의 샘플이 출력\r\n",
    "# 각 샘플의 길이는 20이며\r\n",
    "# 다시 말해 하나의 미니 배치 크기는 (5 * 20)임"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. <pad>토큰이 사용되는 경우\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 맨 처음 feild를 정의할 때 길이를 20이 아닌 150으로 하면 padding이 0으로 채워지는 것을 확인 할 수 있음"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
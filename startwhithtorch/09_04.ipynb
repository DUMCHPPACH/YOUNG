{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "09_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdhEcBWkmAv7bipuhRwBJl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('chch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 04. 영어/한국어 Word2Vec 훈련시키기\n",
        "---\n",
        "gensim 패키지에서 Word2Vec은 이미 구현되어져 있으므로 별도의 word2vec을 구현할 필요 없이 손쉽게 훈련 가능"
      ],
      "metadata": {
        "id": "K4PjAmayepuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# 1. 영어 Word2Vec 만들기\r\n",
        "# 영어 데이터를 다운 받아 직접 word2vec 작업을 진행\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\lemon\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agmtMyNIeuZB",
        "outputId": "8eac3138-8b4e-4951-df3f-cbacc68b6c40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import urllib.request\r\n",
        "import zipfile\r\n",
        "from lxml import etree\r\n",
        "import re\r\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "outputs": [],
      "metadata": {
        "id": "K0b4LcTDfFwU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# 훈련 데이터\r\n",
        "# 링크 : https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\r\n",
        "# 위 파일 압축을 풀면 ted_en-2016408.xml 파일을 얻을 수 있음\r\n",
        "\r\n",
        "datapath = 'D:/chch/startwhithtorch/datafolder/'\r\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml',\r\n",
        "                           filename = datapath + 'ted_en-2016408.xml')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('D:/chch/startwhithtorch/datafolder/ted_en-2016408.xml',\n",
              " <http.client.HTTPMessage at 0x256b2ab1b80>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slRFPWBcfX6R",
        "outputId": "cdd523f6-727f-42ac-90ee-699474339d44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# 해당 파일은 .xml로 우리가 원하는 자연어만 얻기 위해서는 전처리가 필요하다.\r\n",
        "# 얻고자 하는 실질적인 데이터는 영어문장으로만 구성된 내용을 담고 있는\r\n",
        "# <content> 와 </content> 사이의 내용이다.\r\n",
        "# 추가로 사이의 내용에서 (Laughter)나 (Applause)와 같은 배경음을 나타내는 단어도 제거해야 한다."
      ],
      "outputs": [],
      "metadata": {
        "id": "gC7GXhhgiLDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xml 파일 예시\r\n",
        "\r\n",
        "<file id=\"1\">  \r\n",
        "  <head>  \r\n",
        "<url>http://www.ted.com/talks/knut_haanaes_two_reasons_companies_fail_and_how_to_avoid_them</url>  \r\n",
        "       <pagesize>72832</pagesize>  \r\n",
        "... xml 문법 중략 ...  \r\n",
        "<content>  \r\n",
        "Here are two reasons companies fail: they only do more of the same, or they only do what's new.  \r\n",
        "To me the real, real solution to quality growth is figuring out the balance between two activities:  \r\n",
        "... content 내용 중략 ...  \r\n",
        "To me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap,   small electronic calculators in Japan that they used to double-check their calculators.   \r\n",
        "(Laughter)  \r\n",
        "... content 내용 중략 ...  \r\n",
        "(Applause)  \r\n",
        "</content>  \r\n",
        "</file>  \r\n",
        "<file id=\"2\">  \r\n",
        "    <head>  \r\n",
        "<url>http://www.ted.com/talks/lisa_nip_how_humans_could_evolve_to_survive_in_space<url>  \r\n",
        "... 이하 중략 ...  "
      ],
      "metadata": {
        "id": "GbKYSygajtUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# 훈련 데이터 전처리하기\r\n",
        "targetXML = open(datapath + 'ted_en-2016408.xml', 'r', encoding='UTF8')\r\n",
        "target_text = etree.parse(targetXML)\r\n",
        "\r\n",
        "parse_text = '/n'.join(target_text.xpath('//content/text()'))\r\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\r\n",
        "\r\n",
        "content_text = re.sub(r'/([^)]*/)', '', parse_text)\r\n",
        "# parse_text 를 불러와서 (Audio), (Laughter) 등의 배경음 부분을 제거\r\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거한다는 뜻"
      ],
      "outputs": [],
      "metadata": {
        "id": "uQ7Pmh_RjqDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "len(content_text)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23430418"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d1FLbbnCC7P",
        "outputId": "1d5f7f59-12ec-4cbb-a441-a52ba039790c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "sent_text = sent_tokenize(content_text)\r\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용해 문장 토큰화(sentence tokenize) 진행"
      ],
      "outputs": [],
      "metadata": {
        "id": "1In0UxmFF1OZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "sent_text[:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\",\n",
              " 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation.',\n",
              " 'Both are necessary, but it can be too much of a good thing.',\n",
              " 'Consider Facit.',\n",
              " \"I'm actually old enough to remember them.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msa9SSXkF2rJ",
        "outputId": "dc6d4768-6b94-4ca9-ad49-acf673ad568b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "normalized_text = []\r\n",
        "for string in sent_text :\r\n",
        "    tokens = re.sub(r'[^a-z0-9]+', ' ', string.lower())\r\n",
        "    normalized_text.append(tokens)\r\n",
        "# 각 문장에서 알파벳소문자와 숫자를 제외하고는 블랭크로 바꿈"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ed5tK7HOF3hQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "normalized_text[:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['here are two reasons companies fail they only do more of the same or they only do what s new ',\n",
              " 'to me the real real solution to quality growth is figuring out the balance between two activities exploration and exploitation ',\n",
              " 'both are necessary but it can be too much of a good thing ',\n",
              " 'consider facit ',\n",
              " 'i m actually old enough to remember them ']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i58YzTjGGVwe",
        "outputId": "28f5a8a6-8677-41e3-83ad-b0cbd866f7f3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "result = []\r\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]\r\n",
        "# 각 문장에 대해서 NLTK를 이용해 단어 토큰화 수행"
      ],
      "outputs": [],
      "metadata": {
        "id": "zE7hOiSeGk5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "result[:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['here',\n",
              "  'are',\n",
              "  'two',\n",
              "  'reasons',\n",
              "  'companies',\n",
              "  'fail',\n",
              "  'they',\n",
              "  'only',\n",
              "  'do',\n",
              "  'more',\n",
              "  'of',\n",
              "  'the',\n",
              "  'same',\n",
              "  'or',\n",
              "  'they',\n",
              "  'only',\n",
              "  'do',\n",
              "  'what',\n",
              "  's',\n",
              "  'new'],\n",
              " ['to',\n",
              "  'me',\n",
              "  'the',\n",
              "  'real',\n",
              "  'real',\n",
              "  'solution',\n",
              "  'to',\n",
              "  'quality',\n",
              "  'growth',\n",
              "  'is',\n",
              "  'figuring',\n",
              "  'out',\n",
              "  'the',\n",
              "  'balance',\n",
              "  'between',\n",
              "  'two',\n",
              "  'activities',\n",
              "  'exploration',\n",
              "  'and',\n",
              "  'exploitation'],\n",
              " ['both',\n",
              "  'are',\n",
              "  'necessary',\n",
              "  'but',\n",
              "  'it',\n",
              "  'can',\n",
              "  'be',\n",
              "  'too',\n",
              "  'much',\n",
              "  'of',\n",
              "  'a',\n",
              "  'good',\n",
              "  'thing'],\n",
              " ['consider', 'facit'],\n",
              " ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJFzqW7DGyAw",
        "outputId": "b56da339-1846-42b3-adee-585d48403ead"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "print(f'총 샘플의 개수: {len(result)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수: 265335\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLhG6zEAG66Q",
        "outputId": "e36af970-8cf1-4a2b-f23c-cf63ff7a5edd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# 3) Word2Vec 훈련시키기\r\n",
        "from gensim.models import Word2Vec, KeyedVectors\r\n",
        "model = Word2Vec(\r\n",
        "                 sentences = result,    # 훈련시킬 문장셋\r\n",
        "                                        # 각 문장마다 하나의 토큰 list를 생성하며 토큰 list의 개수는 문장 개수 n개 만큼 생성하여 sentences에 저장함\r\n",
        "                 vector_size = 100,     # 워드 벡터의 특징 값, 워드 벡터의 차원\r\n",
        "                 window = 5,            # 현재 단어와 예측 단어의 최대 거리\r\n",
        "                 min_count = 5,         # 이 수보다 낮은 빈도수의 단어는 무시\r\n",
        "                 workers = 4,           # 모델 생성시 사용할 쓰레드 개수\r\n",
        "                 sg = 0                 # 1 = skip-gram / 0 = CBOW\r\n",
        "                 )"
      ],
      "outputs": [],
      "metadata": {
        "id": "kordvkKoHIDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# 학습을 했으니 이용해보자\r\n",
        "\r\n",
        "# .wv.most_similar()로 가장 유사한 단어들을 출력해보자\r\n",
        "model_result = model.wv.most_similar('woman')\r\n",
        "print(model_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('man', 0.8601292967796326), ('girl', 0.8386016488075256), ('lady', 0.8307408094406128), ('boy', 0.7759738564491272), ('soldier', 0.7337160110473633), ('child', 0.7305009365081787), ('kid', 0.7267239093780518), ('gentleman', 0.7170665264129639), ('doctor', 0.7078558802604675), ('guy', 0.7008314728736877)]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRkVy7U5MyXS",
        "outputId": "cf74211b-6983-4275-c1ce-32de17a1177b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# 4) Word2Vec 모델 저장하고 로드하기\r\n",
        "# 학습한 모델을 언제든 다시 사용할 수 있도록 저장해보자\r\n",
        "\r\n",
        "# 모델 저장\r\n",
        "model.wv.save_word2vec_format('./eng_w2v')\r\n",
        "# 모델 로드\r\n",
        "loaded_model = KeyedVectors.load_word2vec_format('eng_w2v')"
      ],
      "outputs": [],
      "metadata": {
        "id": "vZYMKwOdNHd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# 저장한 모델 불러와서 유사한 단어 뽑아보기\r\n",
        "model_result = loaded_model.most_similar('sky')\r\n",
        "print(model_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('sun', 0.7738822102546692), ('river', 0.7321430444717407), ('sea', 0.7295847535133362), ('ocean', 0.7232835292816162), ('mountain', 0.7224076390266418), ('sand', 0.721751868724823), ('moon', 0.7213958501815796), ('desert', 0.7180595993995667), ('window', 0.7092677354812622), ('lake', 0.7088762521743774)]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdRHYDIANify",
        "outputId": "54a6db5d-b981-4b32-f455-b96a8495e01e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 한국어 Word2Vec 만들기\n",
        "---"
      ],
      "metadata": {
        "id": "ClGTZTdCO-gd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 위키피티아 한국어 덤프 파일을 다운 받아서 한국어로 w2v을 진행해보자"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# 1) 위키피디아 한국어 덤프 파일 다운로드\r\n",
        "# 링크: https://dumps.wikimedia.org/kowiki/latest/\r\n",
        "# 사용할 파일: kowiki-latest-pages-articles.xml.bz2\r\n",
        "\r\n",
        "# >>> wikiko 다운 받았음"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hm5GMXxfO8SR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# 2) 위키피디아 익스트랙터 다운로드\r\n",
        "\r\n",
        "# >>> wikiko 다운 받았음"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 3) 위키피디아 한국어 덤프 파일 변환\r\n",
        "# 위 두개의 파일들을 같은 폴더에 위치시킨 후에 아래 명령어를 실행\r\n",
        "# python -m wikiextractor.wikiextractor.WikiExtractor kowiki-latest-pages-articles.xml.bz2 \r\n",
        "\r\n",
        "# 안 되서 갸~빡침"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}
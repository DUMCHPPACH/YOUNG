{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "09_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdhEcBWkmAv7bipuhRwBJl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('chch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 04. 영어/한국어 Word2Vec 훈련시키기\r\n",
        "---\r\n",
        "gensim 패키지에서 Word2Vec은 이미 구현되어져 있으므로 별도의 word2vec을 구현할 필요 없이 손쉽게 훈련 가능"
      ],
      "metadata": {
        "id": "K4PjAmayepuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# 1. 영어 Word2Vec 만들기\r\n",
        "# 영어 데이터를 다운 받아 직접 word2vec 작업을 진행\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\lemon\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agmtMyNIeuZB",
        "outputId": "8eac3138-8b4e-4951-df3f-cbacc68b6c40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import urllib.request\r\n",
        "import zipfile\r\n",
        "from lxml import etree\r\n",
        "import re\r\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "outputs": [],
      "metadata": {
        "id": "K0b4LcTDfFwU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# 훈련 데이터\r\n",
        "# 링크 : https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\r\n",
        "# 위 파일 압축을 풀면 ted_en-2016408.xml 파일을 얻을 수 있음\r\n",
        "\r\n",
        "datapath = 'D:/chch/startwhithtorch/datafolder/'\r\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml',\r\n",
        "                           filename = datapath + 'ted_en-2016408.xml')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('D:/chch/startwhithtorch/datafolder/ted_en-2016408.xml',\n",
              " <http.client.HTTPMessage at 0x256b2ab1b80>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slRFPWBcfX6R",
        "outputId": "cdd523f6-727f-42ac-90ee-699474339d44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# 해당 파일은 .xml로 우리가 원하는 자연어만 얻기 위해서는 전처리가 필요하다.\r\n",
        "# 얻고자 하는 실질적인 데이터는 영어문장으로만 구성된 내용을 담고 있는\r\n",
        "# <content> 와 </content> 사이의 내용이다.\r\n",
        "# 추가로 사이의 내용에서 (Laughter)나 (Applause)와 같은 배경음을 나타내는 단어도 제거해야 한다."
      ],
      "outputs": [],
      "metadata": {
        "id": "gC7GXhhgiLDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xml 파일 예시\r\n",
        "\r\n",
        "<file id=\"1\">  \r\n",
        "  <head>  \r\n",
        "<url>http://www.ted.com/talks/knut_haanaes_two_reasons_companies_fail_and_how_to_avoid_them</url>  \r\n",
        "       <pagesize>72832</pagesize>  \r\n",
        "... xml 문법 중략 ...  \r\n",
        "<content>  \r\n",
        "Here are two reasons companies fail: they only do more of the same, or they only do what's new.  \r\n",
        "To me the real, real solution to quality growth is figuring out the balance between two activities:  \r\n",
        "... content 내용 중략 ...  \r\n",
        "To me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap,   small electronic calculators in Japan that they used to double-check their calculators.   \r\n",
        "(Laughter)  \r\n",
        "... content 내용 중략 ...  \r\n",
        "(Applause)  \r\n",
        "</content>  \r\n",
        "</file>  \r\n",
        "<file id=\"2\">  \r\n",
        "    <head>  \r\n",
        "<url>http://www.ted.com/talks/lisa_nip_how_humans_could_evolve_to_survive_in_space<url>  \r\n",
        "... 이하 중략 ...  "
      ],
      "metadata": {
        "id": "GbKYSygajtUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# 훈련 데이터 전처리하기\r\n",
        "targetXML = open(datapath + 'ted_en-2016408.xml', 'r', encoding='UTF8')\r\n",
        "target_text = etree.parse(targetXML)\r\n",
        "\r\n",
        "parse_text = '/n'.join(target_text.xpath('//content/text()'))\r\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\r\n",
        "\r\n",
        "content_text = re.sub(r'/([^)]*/)', '', parse_text)\r\n",
        "# parse_text 를 불러와서 (Audio), (Laughter) 등의 배경음 부분을 제거\r\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거한다는 뜻"
      ],
      "outputs": [],
      "metadata": {
        "id": "uQ7Pmh_RjqDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "len(content_text)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23430418"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d1FLbbnCC7P",
        "outputId": "1d5f7f59-12ec-4cbb-a441-a52ba039790c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "sent_text = sent_tokenize(content_text)\r\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용해 문장 토큰화(sentence tokenize) 진행"
      ],
      "outputs": [],
      "metadata": {
        "id": "1In0UxmFF1OZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "sent_text[:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\",\n",
              " 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation.',\n",
              " 'Both are necessary, but it can be too much of a good thing.',\n",
              " 'Consider Facit.',\n",
              " \"I'm actually old enough to remember them.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msa9SSXkF2rJ",
        "outputId": "dc6d4768-6b94-4ca9-ad49-acf673ad568b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "normalized_text = []\r\n",
        "for string in sent_text :\r\n",
        "    tokens = re.sub(r'[^a-z0-9]+', ' ', string.lower())\r\n",
        "    normalized_text.append(tokens)\r\n",
        "# 각 문장에서 알파벳소문자와 숫자를 제외하고는 블랭크로 바꿈"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ed5tK7HOF3hQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "normalized_text[:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['here are two reasons companies fail they only do more of the same or they only do what s new ',\n",
              " 'to me the real real solution to quality growth is figuring out the balance between two activities exploration and exploitation ',\n",
              " 'both are necessary but it can be too much of a good thing ',\n",
              " 'consider facit ',\n",
              " 'i m actually old enough to remember them ']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i58YzTjGGVwe",
        "outputId": "28f5a8a6-8677-41e3-83ad-b0cbd866f7f3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "result = []\r\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]\r\n",
        "# 각 문장에 대해서 NLTK를 이용해 단어 토큰화 수행"
      ],
      "outputs": [],
      "metadata": {
        "id": "zE7hOiSeGk5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "result[:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['here',\n",
              "  'are',\n",
              "  'two',\n",
              "  'reasons',\n",
              "  'companies',\n",
              "  'fail',\n",
              "  'they',\n",
              "  'only',\n",
              "  'do',\n",
              "  'more',\n",
              "  'of',\n",
              "  'the',\n",
              "  'same',\n",
              "  'or',\n",
              "  'they',\n",
              "  'only',\n",
              "  'do',\n",
              "  'what',\n",
              "  's',\n",
              "  'new'],\n",
              " ['to',\n",
              "  'me',\n",
              "  'the',\n",
              "  'real',\n",
              "  'real',\n",
              "  'solution',\n",
              "  'to',\n",
              "  'quality',\n",
              "  'growth',\n",
              "  'is',\n",
              "  'figuring',\n",
              "  'out',\n",
              "  'the',\n",
              "  'balance',\n",
              "  'between',\n",
              "  'two',\n",
              "  'activities',\n",
              "  'exploration',\n",
              "  'and',\n",
              "  'exploitation'],\n",
              " ['both',\n",
              "  'are',\n",
              "  'necessary',\n",
              "  'but',\n",
              "  'it',\n",
              "  'can',\n",
              "  'be',\n",
              "  'too',\n",
              "  'much',\n",
              "  'of',\n",
              "  'a',\n",
              "  'good',\n",
              "  'thing'],\n",
              " ['consider', 'facit'],\n",
              " ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJFzqW7DGyAw",
        "outputId": "b56da339-1846-42b3-adee-585d48403ead"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "print(f'총 샘플의 개수: {len(result)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수: 265335\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLhG6zEAG66Q",
        "outputId": "e36af970-8cf1-4a2b-f23c-cf63ff7a5edd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# 3) Word2Vec 훈련시키기\r\n",
        "from gensim.models import Word2Vec, KeyedVectors\r\n",
        "model = Word2Vec(\r\n",
        "                 sentences = result,    # 훈련시킬 문장셋\r\n",
        "                                        # 각 문장마다 하나의 토큰 list를 생성하며 토큰 list의 개수는 문장 개수 n개 만큼 생성하여 sentences에 저장함\r\n",
        "                 vector_size = 100,     # 워드 벡터의 특징 값, 워드 벡터의 차원\r\n",
        "                 window = 5,            # 현재 단어와 예측 단어의 최대 거리\r\n",
        "                 min_count = 5,         # 이 수보다 낮은 빈도수의 단어는 무시\r\n",
        "                 workers = 4,           # 모델 생성시 사용할 쓰레드 개수\r\n",
        "                 sg = 0                 # 1 = skip-gram / 0 = CBOW\r\n",
        "                 )"
      ],
      "outputs": [],
      "metadata": {
        "id": "kordvkKoHIDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# 학습을 했으니 이용해보자\r\n",
        "\r\n",
        "# .wv.most_similar()로 가장 유사한 단어들을 출력해보자\r\n",
        "model_result = model.wv.most_similar('woman')\r\n",
        "print(model_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('man', 0.8601292967796326), ('girl', 0.8386016488075256), ('lady', 0.8307408094406128), ('boy', 0.7759738564491272), ('soldier', 0.7337160110473633), ('child', 0.7305009365081787), ('kid', 0.7267239093780518), ('gentleman', 0.7170665264129639), ('doctor', 0.7078558802604675), ('guy', 0.7008314728736877)]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRkVy7U5MyXS",
        "outputId": "cf74211b-6983-4275-c1ce-32de17a1177b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# 4) Word2Vec 모델 저장하고 로드하기\r\n",
        "# 학습한 모델을 언제든 다시 사용할 수 있도록 저장해보자\r\n",
        "\r\n",
        "# 모델 저장\r\n",
        "model.wv.save_word2vec_format('./eng_w2v')\r\n",
        "# 모델 로드\r\n",
        "loaded_model = KeyedVectors.load_word2vec_format('eng_w2v')"
      ],
      "outputs": [],
      "metadata": {
        "id": "vZYMKwOdNHd5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# 저장한 모델 불러와서 유사한 단어 뽑아보기\r\n",
        "model_result = loaded_model.most_similar('sky')\r\n",
        "print(model_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('sun', 0.7738822102546692), ('river', 0.7321430444717407), ('sea', 0.7295847535133362), ('ocean', 0.7232835292816162), ('mountain', 0.7224076390266418), ('sand', 0.721751868724823), ('moon', 0.7213958501815796), ('desert', 0.7180595993995667), ('window', 0.7092677354812622), ('lake', 0.7088762521743774)]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdRHYDIANify",
        "outputId": "54a6db5d-b981-4b32-f455-b96a8495e01e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 한국어 Word2Vec 만들기\r\n",
        "---"
      ],
      "metadata": {
        "id": "ClGTZTdCO-gd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# 위키피티아 한국어 덤프 파일을 다운 받아서 한국어로 w2v을 진행해보자"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# 1) 위키피디아 한국어 덤프 파일 다운로드\r\n",
        "# 링크: https://dumps.wikimedia.org/kowiki/latest/\r\n",
        "# 사용할 파일: kowiki-latest-pages-articles.xml.bz2\r\n",
        "\r\n",
        "# >>> wikiko 다운 받았음"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hm5GMXxfO8SR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# 2) 위키피디아 익스트랙터 다운로드\r\n",
        "\r\n",
        "# >>> wikiko 다운 받았음"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# 3) 위키피디아 한국어 덤프 파일 변환\r\n",
        "# 위 두개의 파일들을 같은 폴더에 위치시킨 후에 아래 명령어를 실행\r\n",
        "# python -m wikiextractor.wikiextractor.WikiExtractor kowiki-latest-pages-articles.xml.bz2 \r\n",
        "\r\n",
        "# ----------------------------------------------------------\r\n",
        "# Wikiextractor.py 파일 변경\r\n",
        "# from multiprocessing import Queue, Process, cpu_count\r\n",
        "# ▼\r\n",
        "# from multiprocessing import Queue, Process, cpu_count\r\n",
        "# from multiprocessing.dummy import Queue, Process\r\n",
        "\r\n",
        "# 186\r\n",
        "# return open(filename, 'w')\r\n",
        "# >>\r\n",
        "# return open(filename, 'w', encoding='utf-8')\r\n",
        "\r\n",
        "# 210\r\n",
        "# output = open(output_file, 'w')\r\n",
        "# >>>\r\n",
        "# output = open(output_file, 'w', encoding='utf-8')\r\n",
        "\r\n",
        "# 드디어 해결!!!!!!!! 우예히끼항!"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# 4) 훈련 데이터 만들기\r\n",
        "# AA디렉토리 안의 모든 파일인 wiki00~wiki90에 대해서 wikiAA.txt로 통합해보자\r\n",
        "\r\n",
        "# cmd 에서 아래 커맨드 실행\r\n",
        "# D:/chch/wikiko/text>  # 경로로 들어가서\r\n",
        "# copy AI wikiAI.txt    # 이렇게 AA~AI까지\r\n",
        "\r\n",
        "# 그 다음 이 6개 파일도 하나로 합치자\r\n",
        "# D:/chch/wikiko/text>        # 경로에서\r\n",
        "# copy wikiA* wiki_data.txt   # 하나로 합쳐\r\n",
        "\r\n",
        "# 훈련 데이터 완성!!!"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# 5) 훈련 데이터 전처리 하기\r\n",
        "\r\n",
        "f = open('D:/chch/wikiko/text/wiki_data.txt', encoding='utf-8')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# 파일이 제대로 불러와졌는지 확인\r\n",
        "i = 0\r\n",
        "while True:\r\n",
        "    line = f.readline()\r\n",
        "    if line != '/n':\r\n",
        "        i += 1\r\n",
        "        print('%d번째 줄: '%i + line)\r\n",
        "    if i == 5 :\r\n",
        "        break\r\n",
        "\r\n",
        "f.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1번째 줄: <doc id=\"5\" url=\"https://ko.wikipedia.org/wiki?curid=5\" title=\"지미 카터\">\n",
            "\n",
            "2번째 줄: 지미 카터\n",
            "\n",
            "3번째 줄: 제임스 얼 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39대 대통령 (1977년 ~ 1981년)이다.\n",
            "\n",
            "4번째 줄: 생애.\n",
            "\n",
            "5번째 줄: 어린 시절.\n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "from konlpy.tag import Okt  \r\n",
        "okt=Okt()\r\n",
        "\r\n",
        "fread = open('D:/chch/wikiko/text/wiki_data.txt', encoding='utf-8')\r\n",
        "# 파일을 다시 처음부터 읽음.\r\n",
        "n=0\r\n",
        "result = []\r\n",
        "\r\n",
        "while True:\r\n",
        "    line = fread.readline() #한 줄씩 읽음.\r\n",
        "    if not line: break # 모두 읽으면 while문 종료.\r\n",
        "    n=n+1\r\n",
        "    if n%5000==0: # 5,000의 배수로 While문이 실행될 때마다 몇 번째 While문 실행인지 출력.\r\n",
        "        print(\"%d번째 While문.\"%n)\r\n",
        "    tokenlist = okt.pos(line, stem=True, norm=True) # 단어 토큰화\r\n",
        "    temp=[]\r\n",
        "    for word in tokenlist:\r\n",
        "        if word[1] in [\"Noun\"]: # 명사일 때만\r\n",
        "            temp.append((word[0])) # 해당 단어를 저장함\r\n",
        "\r\n",
        "    if temp: # 만약 이번에 읽은 데이터에 명사가 존재할 경우에만\r\n",
        "      result.append(temp) # 결과에 저장\r\n",
        "      \r\n",
        "fread.close()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000번째 While문.\n",
            "10000번째 While문.\n",
            "15000번째 While문.\n",
            "20000번째 While문.\n",
            "25000번째 While문.\n",
            "30000번째 While문.\n",
            "35000번째 While문.\n",
            "40000번째 While문.\n",
            "45000번째 While문.\n",
            "50000번째 While문.\n",
            "55000번째 While문.\n",
            "60000번째 While문.\n",
            "65000번째 While문.\n",
            "70000번째 While문.\n",
            "75000번째 While문.\n",
            "80000번째 While문.\n",
            "85000번째 While문.\n",
            "90000번째 While문.\n",
            "95000번째 While문.\n",
            "100000번째 While문.\n",
            "105000번째 While문.\n",
            "110000번째 While문.\n",
            "115000번째 While문.\n",
            "120000번째 While문.\n",
            "125000번째 While문.\n",
            "130000번째 While문.\n",
            "135000번째 While문.\n",
            "140000번째 While문.\n",
            "145000번째 While문.\n",
            "150000번째 While문.\n",
            "155000번째 While문.\n",
            "160000번째 While문.\n",
            "165000번째 While문.\n",
            "170000번째 While문.\n",
            "175000번째 While문.\n",
            "180000번째 While문.\n",
            "185000번째 While문.\n",
            "190000번째 While문.\n",
            "195000번째 While문.\n",
            "200000번째 While문.\n",
            "205000번째 While문.\n",
            "210000번째 While문.\n",
            "215000번째 While문.\n",
            "220000번째 While문.\n",
            "225000번째 While문.\n",
            "230000번째 While문.\n",
            "235000번째 While문.\n",
            "240000번째 While문.\n",
            "245000번째 While문.\n",
            "250000번째 While문.\n",
            "255000번째 While문.\n",
            "260000번째 While문.\n",
            "265000번째 While문.\n",
            "270000번째 While문.\n",
            "275000번째 While문.\n",
            "280000번째 While문.\n",
            "285000번째 While문.\n",
            "290000번째 While문.\n",
            "295000번째 While문.\n",
            "300000번째 While문.\n",
            "305000번째 While문.\n",
            "310000번째 While문.\n",
            "315000번째 While문.\n",
            "320000번째 While문.\n",
            "325000번째 While문.\n",
            "330000번째 While문.\n",
            "335000번째 While문.\n",
            "340000번째 While문.\n",
            "345000번째 While문.\n",
            "350000번째 While문.\n",
            "355000번째 While문.\n",
            "360000번째 While문.\n",
            "365000번째 While문.\n",
            "370000번째 While문.\n",
            "375000번째 While문.\n",
            "380000번째 While문.\n",
            "385000번째 While문.\n",
            "390000번째 While문.\n",
            "395000번째 While문.\n",
            "400000번째 While문.\n",
            "405000번째 While문.\n",
            "410000번째 While문.\n",
            "415000번째 While문.\n",
            "420000번째 While문.\n",
            "425000번째 While문.\n",
            "430000번째 While문.\n",
            "435000번째 While문.\n",
            "440000번째 While문.\n",
            "445000번째 While문.\n",
            "450000번째 While문.\n",
            "455000번째 While문.\n",
            "460000번째 While문.\n",
            "465000번째 While문.\n",
            "470000번째 While문.\n",
            "475000번째 While문.\n",
            "480000번째 While문.\n",
            "485000번째 While문.\n",
            "490000번째 While문.\n",
            "495000번째 While문.\n",
            "500000번째 While문.\n",
            "505000번째 While문.\n",
            "510000번째 While문.\n",
            "515000번째 While문.\n",
            "520000번째 While문.\n",
            "525000번째 While문.\n",
            "530000번째 While문.\n",
            "535000번째 While문.\n",
            "540000번째 While문.\n",
            "545000번째 While문.\n",
            "550000번째 While문.\n",
            "555000번째 While문.\n",
            "560000번째 While문.\n",
            "565000번째 While문.\n",
            "570000번째 While문.\n",
            "575000번째 While문.\n",
            "580000번째 While문.\n",
            "585000번째 While문.\n",
            "590000번째 While문.\n",
            "595000번째 While문.\n",
            "600000번째 While문.\n",
            "605000번째 While문.\n",
            "610000번째 While문.\n",
            "615000번째 While문.\n",
            "620000번째 While문.\n",
            "625000번째 While문.\n",
            "630000번째 While문.\n",
            "635000번째 While문.\n",
            "640000번째 While문.\n",
            "645000번째 While문.\n",
            "650000번째 While문.\n",
            "655000번째 While문.\n",
            "660000번째 While문.\n",
            "665000번째 While문.\n",
            "670000번째 While문.\n",
            "675000번째 While문.\n",
            "680000번째 While문.\n",
            "685000번째 While문.\n",
            "690000번째 While문.\n",
            "695000번째 While문.\n",
            "700000번째 While문.\n",
            "705000번째 While문.\n",
            "710000번째 While문.\n",
            "715000번째 While문.\n",
            "720000번째 While문.\n",
            "725000번째 While문.\n",
            "730000번째 While문.\n",
            "735000번째 While문.\n",
            "740000번째 While문.\n",
            "745000번째 While문.\n",
            "750000번째 While문.\n",
            "755000번째 While문.\n",
            "760000번째 While문.\n",
            "765000번째 While문.\n",
            "770000번째 While문.\n",
            "775000번째 While문.\n",
            "780000번째 While문.\n",
            "785000번째 While문.\n",
            "790000번째 While문.\n",
            "795000번째 While문.\n",
            "800000번째 While문.\n",
            "805000번째 While문.\n",
            "810000번째 While문.\n",
            "815000번째 While문.\n",
            "820000번째 While문.\n",
            "825000번째 While문.\n",
            "830000번째 While문.\n",
            "835000번째 While문.\n",
            "840000번째 While문.\n",
            "845000번째 While문.\n",
            "850000번째 While문.\n",
            "855000번째 While문.\n",
            "860000번째 While문.\n",
            "865000번째 While문.\n",
            "870000번째 While문.\n",
            "875000번째 While문.\n",
            "880000번째 While문.\n",
            "885000번째 While문.\n",
            "890000번째 While문.\n",
            "895000번째 While문.\n",
            "900000번째 While문.\n",
            "905000번째 While문.\n",
            "910000번째 While문.\n",
            "915000번째 While문.\n",
            "920000번째 While문.\n",
            "925000번째 While문.\n",
            "930000번째 While문.\n",
            "935000번째 While문.\n",
            "940000번째 While문.\n",
            "945000번째 While문.\n",
            "950000번째 While문.\n",
            "955000번째 While문.\n",
            "960000번째 While문.\n",
            "965000번째 While문.\n",
            "970000번째 While문.\n",
            "975000번째 While문.\n",
            "980000번째 While문.\n",
            "985000번째 While문.\n",
            "990000번째 While문.\n",
            "995000번째 While문.\n",
            "1000000번째 While문.\n",
            "1005000번째 While문.\n",
            "1010000번째 While문.\n",
            "1015000번째 While문.\n",
            "1020000번째 While문.\n",
            "1025000번째 While문.\n",
            "1030000번째 While문.\n",
            "1035000번째 While문.\n",
            "1040000번째 While문.\n",
            "1045000번째 While문.\n",
            "1050000번째 While문.\n",
            "1055000번째 While문.\n",
            "1060000번째 While문.\n",
            "1065000번째 While문.\n",
            "1070000번째 While문.\n",
            "1075000번째 While문.\n",
            "1080000번째 While문.\n",
            "1085000번째 While문.\n",
            "1090000번째 While문.\n",
            "1095000번째 While문.\n",
            "1100000번째 While문.\n",
            "1105000번째 While문.\n",
            "1110000번째 While문.\n",
            "1115000번째 While문.\n",
            "1120000번째 While문.\n",
            "1125000번째 While문.\n",
            "1130000번째 While문.\n",
            "1135000번째 While문.\n",
            "1140000번째 While문.\n",
            "1145000번째 While문.\n",
            "1150000번째 While문.\n",
            "1155000번째 While문.\n",
            "1160000번째 While문.\n",
            "1165000번째 While문.\n",
            "1170000번째 While문.\n",
            "1175000번째 While문.\n",
            "1180000번째 While문.\n",
            "1185000번째 While문.\n",
            "1190000번째 While문.\n",
            "1195000번째 While문.\n",
            "1200000번째 While문.\n",
            "1205000번째 While문.\n",
            "1210000번째 While문.\n",
            "1215000번째 While문.\n",
            "1220000번째 While문.\n",
            "1225000번째 While문.\n",
            "1230000번째 While문.\n",
            "1235000번째 While문.\n",
            "1240000번째 While문.\n",
            "1245000번째 While문.\n",
            "1250000번째 While문.\n",
            "1255000번째 While문.\n",
            "1260000번째 While문.\n",
            "1265000번째 While문.\n",
            "1270000번째 While문.\n",
            "1275000번째 While문.\n",
            "1280000번째 While문.\n",
            "1285000번째 While문.\n",
            "1290000번째 While문.\n",
            "1295000번째 While문.\n",
            "1300000번째 While문.\n",
            "1305000번째 While문.\n",
            "1310000번째 While문.\n",
            "1315000번째 While문.\n",
            "1320000번째 While문.\n",
            "1325000번째 While문.\n",
            "1330000번째 While문.\n",
            "1335000번째 While문.\n",
            "1340000번째 While문.\n",
            "1345000번째 While문.\n",
            "1350000번째 While문.\n",
            "1355000번째 While문.\n",
            "1360000번째 While문.\n",
            "1365000번째 While문.\n",
            "1370000번째 While문.\n",
            "1375000번째 While문.\n",
            "1380000번째 While문.\n",
            "1385000번째 While문.\n",
            "1390000번째 While문.\n",
            "1395000번째 While문.\n",
            "1400000번째 While문.\n",
            "1405000번째 While문.\n",
            "1410000번째 While문.\n",
            "1415000번째 While문.\n",
            "1420000번째 While문.\n",
            "1425000번째 While문.\n",
            "1430000번째 While문.\n",
            "1435000번째 While문.\n",
            "1440000번째 While문.\n",
            "1445000번째 While문.\n",
            "1450000번째 While문.\n",
            "1455000번째 While문.\n",
            "1460000번째 While문.\n",
            "1465000번째 While문.\n",
            "1470000번째 While문.\n",
            "1475000번째 While문.\n",
            "1480000번째 While문.\n",
            "1485000번째 While문.\n",
            "1490000번째 While문.\n",
            "1495000번째 While문.\n",
            "1500000번째 While문.\n",
            "1505000번째 While문.\n",
            "1510000번째 While문.\n",
            "1515000번째 While문.\n",
            "1520000번째 While문.\n",
            "1525000번째 While문.\n",
            "1530000번째 While문.\n",
            "1535000번째 While문.\n",
            "1540000번째 While문.\n",
            "1545000번째 While문.\n",
            "1550000번째 While문.\n",
            "1555000번째 While문.\n",
            "1560000번째 While문.\n",
            "1565000번째 While문.\n",
            "1570000번째 While문.\n",
            "1575000번째 While문.\n",
            "1580000번째 While문.\n",
            "1585000번째 While문.\n",
            "1590000번째 While문.\n",
            "1595000번째 While문.\n",
            "1600000번째 While문.\n",
            "1605000번째 While문.\n",
            "1610000번째 While문.\n",
            "1615000번째 While문.\n",
            "1620000번째 While문.\n",
            "1625000번째 While문.\n",
            "1630000번째 While문.\n",
            "1635000번째 While문.\n",
            "1640000번째 While문.\n",
            "1645000번째 While문.\n",
            "1650000번째 While문.\n",
            "1655000번째 While문.\n",
            "1660000번째 While문.\n",
            "1665000번째 While문.\n",
            "1670000번째 While문.\n",
            "1675000번째 While문.\n",
            "1680000번째 While문.\n",
            "1685000번째 While문.\n",
            "1690000번째 While문.\n",
            "1695000번째 While문.\n",
            "1700000번째 While문.\n",
            "1705000번째 While문.\n",
            "1710000번째 While문.\n",
            "1715000번째 While문.\n",
            "1720000번째 While문.\n",
            "1725000번째 While문.\n",
            "1730000번째 While문.\n",
            "1735000번째 While문.\n",
            "1740000번째 While문.\n",
            "1745000번째 While문.\n",
            "1750000번째 While문.\n",
            "1755000번째 While문.\n",
            "1760000번째 While문.\n",
            "1765000번째 While문.\n",
            "1770000번째 While문.\n",
            "1775000번째 While문.\n",
            "1780000번째 While문.\n",
            "1785000번째 While문.\n",
            "1790000번째 While문.\n",
            "1795000번째 While문.\n",
            "1800000번째 While문.\n",
            "1805000번째 While문.\n",
            "1810000번째 While문.\n",
            "1815000번째 While문.\n",
            "1820000번째 While문.\n",
            "1825000번째 While문.\n",
            "1830000번째 While문.\n",
            "1835000번째 While문.\n",
            "1840000번째 While문.\n",
            "1845000번째 While문.\n",
            "1850000번째 While문.\n",
            "1855000번째 While문.\n",
            "1860000번째 While문.\n",
            "1865000번째 While문.\n",
            "1870000번째 While문.\n",
            "1875000번째 While문.\n",
            "1880000번째 While문.\n",
            "1885000번째 While문.\n",
            "1890000번째 While문.\n",
            "1895000번째 While문.\n",
            "1900000번째 While문.\n",
            "1905000번째 While문.\n",
            "1910000번째 While문.\n",
            "1915000번째 While문.\n",
            "1920000번째 While문.\n",
            "1925000번째 While문.\n",
            "1930000번째 While문.\n",
            "1935000번째 While문.\n",
            "1940000번째 While문.\n",
            "1945000번째 While문.\n",
            "1950000번째 While문.\n",
            "1955000번째 While문.\n",
            "1960000번째 While문.\n",
            "1965000번째 While문.\n",
            "1970000번째 While문.\n",
            "1975000번째 While문.\n",
            "1980000번째 While문.\n",
            "1985000번째 While문.\n",
            "1990000번째 While문.\n",
            "1995000번째 While문.\n",
            "2000000번째 While문.\n",
            "2005000번째 While문.\n",
            "2010000번째 While문.\n",
            "2015000번째 While문.\n",
            "2020000번째 While문.\n",
            "2025000번째 While문.\n",
            "2030000번째 While문.\n",
            "2035000번째 While문.\n",
            "2040000번째 While문.\n",
            "2045000번째 While문.\n",
            "2050000번째 While문.\n",
            "2055000번째 While문.\n",
            "2060000번째 While문.\n",
            "2065000번째 While문.\n",
            "2070000번째 While문.\n",
            "2075000번째 While문.\n",
            "2080000번째 While문.\n",
            "2085000번째 While문.\n",
            "2090000번째 While문.\n",
            "2095000번째 While문.\n",
            "2100000번째 While문.\n",
            "2105000번째 While문.\n",
            "2110000번째 While문.\n",
            "2115000번째 While문.\n",
            "2120000번째 While문.\n",
            "2125000번째 While문.\n",
            "2130000번째 While문.\n",
            "2135000번째 While문.\n",
            "2140000번째 While문.\n",
            "2145000번째 While문.\n",
            "2150000번째 While문.\n",
            "2155000번째 While문.\n",
            "2160000번째 While문.\n",
            "2165000번째 While문.\n",
            "2170000번째 While문.\n",
            "2175000번째 While문.\n",
            "2180000번째 While문.\n",
            "2185000번째 While문.\n",
            "2190000번째 While문.\n",
            "2195000번째 While문.\n",
            "2200000번째 While문.\n",
            "2205000번째 While문.\n",
            "2210000번째 While문.\n",
            "2215000번째 While문.\n",
            "2220000번째 While문.\n",
            "2225000번째 While문.\n",
            "2230000번째 While문.\n",
            "2235000번째 While문.\n",
            "2240000번째 While문.\n",
            "2245000번째 While문.\n",
            "2250000번째 While문.\n",
            "2255000번째 While문.\n",
            "2260000번째 While문.\n",
            "2265000번째 While문.\n",
            "2270000번째 While문.\n",
            "2275000번째 While문.\n",
            "2280000번째 While문.\n",
            "2285000번째 While문.\n",
            "2290000번째 While문.\n",
            "2295000번째 While문.\n",
            "2300000번째 While문.\n",
            "2305000번째 While문.\n",
            "2310000번째 While문.\n",
            "2315000번째 While문.\n",
            "2320000번째 While문.\n",
            "2325000번째 While문.\n",
            "2330000번째 While문.\n",
            "2335000번째 While문.\n",
            "2340000번째 While문.\n",
            "2345000번째 While문.\n",
            "2350000번째 While문.\n",
            "2355000번째 While문.\n",
            "2360000번째 While문.\n",
            "2365000번째 While문.\n",
            "2370000번째 While문.\n",
            "2375000번째 While문.\n",
            "2380000번째 While문.\n",
            "2385000번째 While문.\n",
            "2390000번째 While문.\n",
            "2395000번째 While문.\n",
            "2400000번째 While문.\n",
            "2405000번째 While문.\n",
            "2410000번째 While문.\n",
            "2415000번째 While문.\n",
            "2420000번째 While문.\n",
            "2425000번째 While문.\n",
            "2430000번째 While문.\n",
            "2435000번째 While문.\n",
            "2440000번째 While문.\n",
            "2445000번째 While문.\n",
            "2450000번째 While문.\n",
            "2455000번째 While문.\n",
            "2460000번째 While문.\n",
            "2465000번째 While문.\n",
            "2470000번째 While문.\n",
            "2475000번째 While문.\n",
            "2480000번째 While문.\n",
            "2485000번째 While문.\n",
            "2490000번째 While문.\n",
            "2495000번째 While문.\n",
            "2500000번째 While문.\n",
            "2505000번째 While문.\n",
            "2510000번째 While문.\n",
            "2515000번째 While문.\n",
            "2520000번째 While문.\n",
            "2525000번째 While문.\n",
            "2530000번째 While문.\n",
            "2535000번째 While문.\n",
            "2540000번째 While문.\n",
            "2545000번째 While문.\n",
            "2550000번째 While문.\n",
            "2555000번째 While문.\n",
            "2560000번째 While문.\n",
            "2565000번째 While문.\n",
            "2570000번째 While문.\n",
            "2575000번째 While문.\n",
            "2580000번째 While문.\n",
            "2585000번째 While문.\n",
            "2590000번째 While문.\n",
            "2595000번째 While문.\n",
            "2600000번째 While문.\n",
            "2605000번째 While문.\n",
            "2610000번째 While문.\n",
            "2615000번째 While문.\n",
            "2620000번째 While문.\n",
            "2625000번째 While문.\n",
            "2630000번째 While문.\n",
            "2635000번째 While문.\n",
            "2640000번째 While문.\n",
            "2645000번째 While문.\n",
            "2650000번째 While문.\n",
            "2655000번째 While문.\n",
            "2660000번째 While문.\n",
            "2665000번째 While문.\n",
            "2670000번째 While문.\n",
            "2675000번째 While문.\n",
            "2680000번째 While문.\n",
            "2685000번째 While문.\n",
            "2690000번째 While문.\n",
            "2695000번째 While문.\n",
            "2700000번째 While문.\n",
            "2705000번째 While문.\n",
            "2710000번째 While문.\n",
            "2715000번째 While문.\n",
            "2720000번째 While문.\n",
            "2725000번째 While문.\n",
            "2730000번째 While문.\n",
            "2735000번째 While문.\n",
            "2740000번째 While문.\n",
            "2745000번째 While문.\n",
            "2750000번째 While문.\n",
            "2755000번째 While문.\n",
            "2760000번째 While문.\n",
            "2765000번째 While문.\n",
            "2770000번째 While문.\n",
            "2775000번째 While문.\n",
            "2780000번째 While문.\n",
            "2785000번째 While문.\n",
            "2790000번째 While문.\n",
            "2795000번째 While문.\n",
            "2800000번째 While문.\n",
            "2805000번째 While문.\n",
            "2810000번째 While문.\n",
            "2815000번째 While문.\n",
            "2820000번째 While문.\n",
            "2825000번째 While문.\n",
            "2830000번째 While문.\n",
            "2835000번째 While문.\n",
            "2840000번째 While문.\n",
            "2845000번째 While문.\n",
            "2850000번째 While문.\n",
            "2855000번째 While문.\n",
            "2860000번째 While문.\n",
            "2865000번째 While문.\n",
            "2870000번째 While문.\n",
            "2875000번째 While문.\n",
            "2880000번째 While문.\n",
            "2885000번째 While문.\n",
            "2890000번째 While문.\n",
            "2895000번째 While문.\n",
            "2900000번째 While문.\n",
            "2905000번째 While문.\n",
            "2910000번째 While문.\n",
            "2915000번째 While문.\n",
            "2920000번째 While문.\n",
            "2925000번째 While문.\n",
            "2930000번째 While문.\n",
            "2935000번째 While문.\n",
            "2940000번째 While문.\n",
            "2945000번째 While문.\n",
            "2950000번째 While문.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12964/21862668.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 5,000의 배수로 While문이 실행될 때마다 몇 번째 While문 실행인지 출력.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d번째 While문.\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtokenlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 단어 토큰화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\chch\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \"\"\"\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         tokens = self.jki.tokenize(\n\u001b[0m\u001b[0;32m     61\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# 너무 오래 걸려서 멈춤!\r\n",
        "fread.close()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(result)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 1860178\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# 6) Word2Vec 훈련시키기\r\n",
        "from gensim.models import Word2Vec\r\n",
        "model = Word2Vec(result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "model_result1 = model.wv.most_similar('대한민국')\r\n",
        "print(model_result1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('한국', 0.6795631647109985), ('우리나라', 0.5766524076461792), ('조선민주주의인민공화국', 0.5732355713844299), ('재외동포', 0.5540997982025146), ('부산광역시', 0.5316900610923767), ('국내', 0.5233590602874756), ('관세청', 0.516149640083313), ('대구광역시', 0.4936351776123047), ('방위사업청', 0.49209317564964294), ('여성가족부', 0.49202823638916016)]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "model_result2 = model.wv.most_similar('고양이')\r\n",
        "print(model_result2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('토끼', 0.810920238494873), ('강아지', 0.7959395051002502), ('애완동물', 0.7670261263847351), ('거북이', 0.7571203708648682), ('거위', 0.7559707164764404), ('애완견', 0.741983950138092), ('울음소리', 0.7234353423118591), ('사냥개', 0.716405987739563), ('개구리', 0.7151011228561401), ('햄스터', 0.6961157917976379)]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 사전 훈련된 Word2Vec 임베딩(Pre-trained Word2Vec embedding) 소개\r\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# 방대한 데이터로 사전에 훈련된 워드 임베딩을 가지고 와서 해당 벡터들의 값을 원하는 작업에 사용 가능"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# 1) 영어\r\n",
        "\r\n",
        "# 구글이 제공하는 사전 훈련된 W2V 모델을 사용해보자\r\n",
        "google_w2v = 'D:/chchdata/dataset/GoogleNews-vectors-negative300.bin'"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "import gensim\r\n",
        "\r\n",
        "# 모델을 로드 \r\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(google_w2v, binary=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# 모델 크기 확인\r\n",
        "print(model.vectors.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000000, 300)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# 모델 크기는 3,000,000 * 300 인데 3백만 개의 단어와 각 단어의 차원은 300이라는 뜻"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# 두 단어의 유사도 계산하기\r\n",
        "print(model.similarity('this', 'is'))\r\n",
        "print(model.similarity('book', 'books'))\r\n",
        "print(model.similarity('book', 'duck'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.40797037\n",
            "0.73791784\n",
            "0.041631036\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# 단어 book의 벡터 출력\r\n",
        "print(model['book'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.11279297 -0.02612305 -0.04492188  0.06982422  0.140625    0.03039551\n",
            " -0.04370117  0.24511719  0.08740234 -0.05053711  0.23144531 -0.07470703\n",
            "  0.21875     0.03466797 -0.14550781  0.05761719  0.00671387 -0.00701904\n",
            "  0.13183594 -0.25390625  0.14355469 -0.140625   -0.03564453 -0.21289062\n",
            " -0.24804688  0.04980469 -0.09082031  0.14453125  0.05712891 -0.10400391\n",
            " -0.19628906 -0.20507812 -0.27539062  0.03063965  0.20117188  0.17382812\n",
            "  0.09130859 -0.10107422  0.22851562 -0.04077148  0.02709961 -0.00106049\n",
            "  0.02709961  0.34179688 -0.13183594 -0.078125    0.02197266 -0.18847656\n",
            " -0.17480469 -0.05566406 -0.20898438  0.04858398 -0.07617188 -0.15625\n",
            " -0.05419922  0.01672363 -0.02722168 -0.11132812 -0.03588867 -0.18359375\n",
            "  0.28710938  0.01757812  0.02185059 -0.05664062 -0.01251221  0.01708984\n",
            " -0.21777344 -0.06787109  0.04711914 -0.00668335  0.08544922 -0.02209473\n",
            "  0.31835938  0.01794434 -0.02246094 -0.03051758 -0.09570312  0.24414062\n",
            "  0.20507812  0.05419922  0.29101562  0.03637695  0.04956055 -0.06689453\n",
            "  0.09277344 -0.10595703 -0.04370117  0.19726562 -0.03015137  0.05615234\n",
            "  0.08544922 -0.09863281 -0.02392578 -0.08691406 -0.22460938 -0.16894531\n",
            "  0.09521484 -0.0612793  -0.03015137 -0.265625   -0.13378906  0.00139618\n",
            "  0.01794434  0.10107422  0.13964844  0.06445312 -0.09765625 -0.11376953\n",
            " -0.24511719 -0.15722656  0.00457764  0.12988281 -0.03540039 -0.08105469\n",
            "  0.18652344  0.03125    -0.09326172 -0.04760742  0.23730469  0.11083984\n",
            "  0.08691406  0.01916504  0.21386719 -0.0065918  -0.08984375 -0.02502441\n",
            " -0.09863281 -0.05639648 -0.26757812  0.19335938 -0.08886719 -0.25976562\n",
            "  0.05957031 -0.10742188  0.09863281  0.1484375   0.04101562  0.00340271\n",
            " -0.06591797 -0.02941895  0.20019531 -0.00521851  0.02355957 -0.13671875\n",
            " -0.12597656 -0.10791016  0.0067749   0.15917969  0.0145874  -0.15136719\n",
            "  0.07519531 -0.02905273  0.01843262  0.20800781  0.25195312 -0.11523438\n",
            " -0.23535156  0.04101562 -0.11035156  0.02905273  0.22460938 -0.04272461\n",
            "  0.09667969  0.11865234  0.08007812  0.07958984  0.3125     -0.14941406\n",
            " -0.234375    0.06079102  0.06982422 -0.14355469 -0.05834961 -0.36914062\n",
            " -0.10595703  0.00738525  0.24023438 -0.10400391 -0.02124023  0.05712891\n",
            " -0.11621094 -0.16894531 -0.06396484 -0.12060547  0.08105469 -0.13769531\n",
            " -0.08447266  0.12792969 -0.15429688  0.17871094  0.2421875  -0.06884766\n",
            "  0.03320312  0.04394531 -0.04589844  0.03686523 -0.07421875 -0.01635742\n",
            " -0.24121094 -0.08203125 -0.01733398  0.0291748   0.10742188  0.11279297\n",
            "  0.12890625  0.01416016 -0.28710938  0.16503906 -0.25585938  0.2109375\n",
            " -0.19238281  0.22363281  0.04541016  0.00872803  0.11376953  0.375\n",
            "  0.09765625  0.06201172  0.12109375 -0.24316406  0.203125    0.12158203\n",
            "  0.08642578  0.01782227  0.17382812  0.01855469  0.03613281 -0.02124023\n",
            " -0.02905273 -0.04541016  0.1796875   0.06494141 -0.13378906 -0.09228516\n",
            "  0.02172852  0.02099609  0.07226562  0.3046875  -0.27539062 -0.30078125\n",
            "  0.08691406 -0.22949219  0.0546875  -0.34179688 -0.00680542 -0.0291748\n",
            " -0.03222656  0.16210938  0.01141357  0.23339844 -0.0859375  -0.06494141\n",
            "  0.15039062  0.17675781  0.08251953 -0.26757812 -0.11669922  0.01330566\n",
            "  0.01818848  0.10009766 -0.09570312  0.109375   -0.16992188 -0.23046875\n",
            " -0.22070312  0.0625      0.03662109 -0.125       0.05151367 -0.18847656\n",
            "  0.22949219  0.26367188 -0.09814453  0.06176758  0.11669922  0.23046875\n",
            "  0.32617188  0.02038574 -0.03735352 -0.12255859  0.296875   -0.25\n",
            " -0.08544922 -0.03149414  0.38085938  0.02929688 -0.265625    0.42382812\n",
            " -0.1484375   0.14355469 -0.03125     0.00717163 -0.16601562 -0.15820312\n",
            "  0.03637695 -0.16796875 -0.01483154  0.09667969 -0.05761719 -0.00515747]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# 2) 한국어\r\n",
        "import gensim\r\n",
        "\r\n",
        "ko_pre_path = 'D:/chchdata/dataset/kowiki_pre_w2v.bin'"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# 불러올 때 에러 발생\r\n",
        "# >> AttributeError: Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\lemon\\\\anaconda3\\\\envs\\\\chch\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>\r\n",
        "\r\n",
        "# gensim 버전이 4점대라서 그런거니 3점대로 내리자\r\n",
        "# 원래 4.1.2\r\n",
        "# pip install --upgrade --user gensim==3.8.3\r\n",
        "\r\n",
        "# 해결!"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# 저장한 파일을 모델로 지정\r\n",
        "model = gensim.models.Word2Vec.load(ko_pre_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "result=model.wv.most_similar(\"강아지\")\r\n",
        "print(result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('고양이', 0.7290452718734741), ('거위', 0.7185635566711426), ('토끼', 0.7056223154067993), ('멧돼지', 0.6950401067733765), ('엄마', 0.6934334635734558), ('난쟁이', 0.6806551218032837), ('한마리', 0.6770296096801758), ('아가씨', 0.6750352382659912), ('아빠', 0.6729634404182434), ('목걸이', 0.6512460708618164)]\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}
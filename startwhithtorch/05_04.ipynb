{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# https://wikidocs.net/60575"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "# 04. 소프트맥스 회귀 구현하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 소프트맥스를 low level과 F.cross_entropy를 사용해 구현해보자"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "torch.manual_seed(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x275b3593f78>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 훈련 데이터 선언\r\n",
    "x_train = [[1, 2, 1, 1],\r\n",
    "           [2, 1, 3, 2],\r\n",
    "           [3, 1, 3, 4],\r\n",
    "           [4, 1, 5, 5],\r\n",
    "           [1, 7, 5, 5],\r\n",
    "           [1, 2, 5, 6],\r\n",
    "           [1, 6, 6, 6],\r\n",
    "           [1, 7, 7, 7]]\r\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\r\n",
    "x_train = torch.FloatTensor(x_train)\r\n",
    "y_train = torch.LongTensor(y_train)     # 선언할 때 부터 long 타입으로\r\n",
    "\r\n",
    "# x에 4개의 특성이 있으며 총 8개의 샘플이 존재\r\n",
    "# y에는 0,1,2의 레이블이 존재"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# -----------------------------------------\r\n",
    "# Low level로 구현하기\r\n",
    "\r\n",
    "# 데이터 확인\r\n",
    "print(x_train.shape)\r\n",
    "print(y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# y데이터 원핫 인코딩 진행\r\n",
    "\r\n",
    "y_one_hot = torch.zeros(8, 3)\r\n",
    "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\r\n",
    "print(y_one_hot.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# x = (8,4)   y = (8,3) 이므로 W 행렬의 크기는 4*3 이어야 함\r\n",
    "\r\n",
    "# 모델 초기화\r\n",
    "W = torch.zeros((4, 3), requires_grad=True)\r\n",
    "b = torch.zeros(1, requires_grad=True)\r\n",
    "\r\n",
    "# optimizer 설정\r\n",
    "optimizer = optim.SGD([W, b], lr = 0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 학습\r\n",
    "\r\n",
    "nb_epochs = 1000\r\n",
    "for epoch in range(nb_epochs + 1):\r\n",
    "\r\n",
    "    # hypothesis\r\n",
    "    hypothesis = F.softmax(x_train.matmul(W) + b , dim=1)\r\n",
    "\r\n",
    "    # 비용 함수\r\n",
    "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\r\n",
    "\r\n",
    "    # cost로 H(x) 개선\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # 100번 마다 로그 출력\r\n",
    "    if epoch % 100 == 0 :\r\n",
    "        print('Epoch {:4}/{}  Cost {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/1000  Cost 1.098612\n",
      "Epoch  100/1000  Cost 0.761050\n",
      "Epoch  200/1000  Cost 0.689991\n",
      "Epoch  300/1000  Cost 0.643229\n",
      "Epoch  400/1000  Cost 0.604117\n",
      "Epoch  500/1000  Cost 0.568255\n",
      "Epoch  600/1000  Cost 0.533922\n",
      "Epoch  700/1000  Cost 0.500291\n",
      "Epoch  800/1000  Cost 0.466908\n",
      "Epoch  900/1000  Cost 0.433507\n",
      "Epoch 1000/1000  Cost 0.399962\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# ----------------------------------------\r\n",
    "# High level로 구현하기"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# F.cross_entropy 는 그 자체로 소프트 맥스를 포함한다!\r\n",
    "\r\n",
    "# 모델 초기화\r\n",
    "W = torch.zeros((4, 3), requires_grad=True)\r\n",
    "b = torch.zeros(1, requires_grad=True)\r\n",
    "\r\n",
    "# optimizer 설정\r\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\r\n",
    "\r\n",
    "nb_epochs = 1000\r\n",
    "for epoch in range(nb_epochs+1):\r\n",
    "\r\n",
    "    # Cost 계산\r\n",
    "    z = x_train.matmul(W) + b\r\n",
    "    cost = F.cross_entropy(z, y_train)\r\n",
    "\r\n",
    "    # cost로 H(x) 개선\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # 100마다 로그 출력\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print('Epoch {:4d}/{}   Cost {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/1000   Cost 1.098612\n",
      "Epoch  100/1000   Cost 0.761050\n",
      "Epoch  200/1000   Cost 0.689991\n",
      "Epoch  300/1000   Cost 0.643229\n",
      "Epoch  400/1000   Cost 0.604117\n",
      "Epoch  500/1000   Cost 0.568255\n",
      "Epoch  600/1000   Cost 0.533922\n",
      "Epoch  700/1000   Cost 0.500291\n",
      "Epoch  800/1000   Cost 0.466908\n",
      "Epoch  900/1000   Cost 0.433507\n",
      "Epoch 1000/1000   Cost 0.399962\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# ------------------------------\r\n",
    "# 소프트맥스 회귀 nn.Module로 구현하기"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# nn.linear()를 모델로 이용해 다중 분류를 만들어보자\r\n",
    "\r\n",
    "model = nn.Linear(4, 3)\r\n",
    "# 4개의 특성을 가지고 3개의 클래스로 분류\r\n",
    "# input_dim = 4, output_dim 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# cost는 F.cross_entropy()를 사용할 것임으로 softmax 함수를 따로 정의하지 않는다\r\n",
    "\r\n",
    "# optimizer 설정\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\r\n",
    "\r\n",
    "nb_epochs = 1000\r\n",
    "for epoch in range(nb_epochs+1):\r\n",
    "\r\n",
    "    # H(x) 계산\r\n",
    "    prediction = model(x_train)\r\n",
    "\r\n",
    "    # cost 계산\r\n",
    "    cost = F.cross_entropy(prediction, y_train)\r\n",
    "\r\n",
    "    # cost로 H(x) 개선\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # 20번마다 로그 출력\r\n",
    "    if epoch % 20 == 0:\r\n",
    "        print('Epoch {:4d}/{}  Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/1000  Cost: 1.616785\n",
      "Epoch   20/1000  Cost: 0.904600\n",
      "Epoch   40/1000  Cost: 0.778017\n",
      "Epoch   60/1000  Cost: 0.722806\n",
      "Epoch   80/1000  Cost: 0.686341\n",
      "Epoch  100/1000  Cost: 0.658891\n",
      "Epoch  120/1000  Cost: 0.636713\n",
      "Epoch  140/1000  Cost: 0.617946\n",
      "Epoch  160/1000  Cost: 0.601539\n",
      "Epoch  180/1000  Cost: 0.586845\n",
      "Epoch  200/1000  Cost: 0.573444\n",
      "Epoch  220/1000  Cost: 0.561047\n",
      "Epoch  240/1000  Cost: 0.549451\n",
      "Epoch  260/1000  Cost: 0.538507\n",
      "Epoch  280/1000  Cost: 0.528102\n",
      "Epoch  300/1000  Cost: 0.518151\n",
      "Epoch  320/1000  Cost: 0.508587\n",
      "Epoch  340/1000  Cost: 0.499357\n",
      "Epoch  360/1000  Cost: 0.490416\n",
      "Epoch  380/1000  Cost: 0.481729\n",
      "Epoch  400/1000  Cost: 0.473266\n",
      "Epoch  420/1000  Cost: 0.465000\n",
      "Epoch  440/1000  Cost: 0.456911\n",
      "Epoch  460/1000  Cost: 0.448979\n",
      "Epoch  480/1000  Cost: 0.441185\n",
      "Epoch  500/1000  Cost: 0.433516\n",
      "Epoch  520/1000  Cost: 0.425956\n",
      "Epoch  540/1000  Cost: 0.418493\n",
      "Epoch  560/1000  Cost: 0.411114\n",
      "Epoch  580/1000  Cost: 0.403808\n",
      "Epoch  600/1000  Cost: 0.396563\n",
      "Epoch  620/1000  Cost: 0.389370\n",
      "Epoch  640/1000  Cost: 0.382218\n",
      "Epoch  660/1000  Cost: 0.375098\n",
      "Epoch  680/1000  Cost: 0.367999\n",
      "Epoch  700/1000  Cost: 0.360914\n",
      "Epoch  720/1000  Cost: 0.353833\n",
      "Epoch  740/1000  Cost: 0.346749\n",
      "Epoch  760/1000  Cost: 0.339651\n",
      "Epoch  780/1000  Cost: 0.332535\n",
      "Epoch  800/1000  Cost: 0.325392\n",
      "Epoch  820/1000  Cost: 0.318218\n",
      "Epoch  840/1000  Cost: 0.311008\n",
      "Epoch  860/1000  Cost: 0.303762\n",
      "Epoch  880/1000  Cost: 0.296482\n",
      "Epoch  900/1000  Cost: 0.289178\n",
      "Epoch  920/1000  Cost: 0.281874\n",
      "Epoch  940/1000  Cost: 0.274609\n",
      "Epoch  960/1000  Cost: 0.267463\n",
      "Epoch  980/1000  Cost: 0.260570\n",
      "Epoch 1000/1000  Cost: 0.254148\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# ------------------------------\r\n",
    "# 4. 소프트맥스 회귀 클래스로 구현하기"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# nn.Module을 상속받은 클래스로 구현하자\r\n",
    "\r\n",
    "class SoftmaxClassfierModel(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(4, 3)  # input 4, output이 3\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.linear(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = SoftmaxClassfierModel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# optimizer 설정\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\r\n",
    "\r\n",
    "nb_epochs = 1000\r\n",
    "for epoch in range(nb_epochs+1):\r\n",
    "\r\n",
    "    # H(x) 계산\r\n",
    "    prediction = model(x_train)\r\n",
    "\r\n",
    "    # cost 계산\r\n",
    "    cost = F.cross_entropy(prediction, y_train)\r\n",
    "\r\n",
    "    # cost로 H(x) 개선\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # 20번 마다 로그 출력\r\n",
    "    if epoch % 20 == 0:\r\n",
    "        print('Epoch {:4d}/{}  Cost {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/1000  Cost 2.637636\n",
      "Epoch   20/1000  Cost 0.887444\n",
      "Epoch   40/1000  Cost 0.773795\n",
      "Epoch   60/1000  Cost 0.714015\n",
      "Epoch   80/1000  Cost 0.675676\n",
      "Epoch  100/1000  Cost 0.647903\n",
      "Epoch  120/1000  Cost 0.625999\n",
      "Epoch  140/1000  Cost 0.607701\n",
      "Epoch  160/1000  Cost 0.591800\n",
      "Epoch  180/1000  Cost 0.577594\n",
      "Epoch  200/1000  Cost 0.564643\n",
      "Epoch  220/1000  Cost 0.552655\n",
      "Epoch  240/1000  Cost 0.541428\n",
      "Epoch  260/1000  Cost 0.530818\n",
      "Epoch  280/1000  Cost 0.520717\n",
      "Epoch  300/1000  Cost 0.511043\n",
      "Epoch  320/1000  Cost 0.501733\n",
      "Epoch  340/1000  Cost 0.492736\n",
      "Epoch  360/1000  Cost 0.484011\n",
      "Epoch  380/1000  Cost 0.475525\n",
      "Epoch  400/1000  Cost 0.467249\n",
      "Epoch  420/1000  Cost 0.459159\n",
      "Epoch  440/1000  Cost 0.451235\n",
      "Epoch  460/1000  Cost 0.443458\n",
      "Epoch  480/1000  Cost 0.435811\n",
      "Epoch  500/1000  Cost 0.428281\n",
      "Epoch  520/1000  Cost 0.420852\n",
      "Epoch  540/1000  Cost 0.413514\n",
      "Epoch  560/1000  Cost 0.406254\n",
      "Epoch  580/1000  Cost 0.399061\n",
      "Epoch  600/1000  Cost 0.391924\n",
      "Epoch  620/1000  Cost 0.384834\n",
      "Epoch  640/1000  Cost 0.377779\n",
      "Epoch  660/1000  Cost 0.370752\n",
      "Epoch  680/1000  Cost 0.363743\n",
      "Epoch  700/1000  Cost 0.356742\n",
      "Epoch  720/1000  Cost 0.349741\n",
      "Epoch  740/1000  Cost 0.342732\n",
      "Epoch  760/1000  Cost 0.335706\n",
      "Epoch  780/1000  Cost 0.328657\n",
      "Epoch  800/1000  Cost 0.321577\n",
      "Epoch  820/1000  Cost 0.314462\n",
      "Epoch  840/1000  Cost 0.307306\n",
      "Epoch  860/1000  Cost 0.300111\n",
      "Epoch  880/1000  Cost 0.292877\n",
      "Epoch  900/1000  Cost 0.285617\n",
      "Epoch  920/1000  Cost 0.278353\n",
      "Epoch  940/1000  Cost 0.271127\n",
      "Epoch  960/1000  Cost 0.264022\n",
      "Epoch  980/1000  Cost 0.257176\n",
      "Epoch 1000/1000  Cost 0.250818\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
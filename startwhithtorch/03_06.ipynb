{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "# 06. 미니 배치와 데이터 로드(Mini Batch and Data Load)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 미니 배치 경사 하강법에 대해 알아보자\r\n",
    "# minibatch gradient descent\r\n",
    "# 배치 경사 하강법 / 미니 배치 경사 하강법\r\n",
    "# 배치 크기는 보통 2의 제곱수를 사용하는데 그 이유는 cpu, gpu 메모리가 2의 배수여서 데이터 송수신의 효율을 높일 수 있기 때문이다..라고 하지만 그렇게 큰 관계가 있을지?\r\n",
    "# batch size : 얼만큼의 크기로 잘라서 들어가느냐\r\n",
    "# iteration : 1 epoch 당 매개변수 업데이트가 몇번 이루어 지냐(batch size에 따라 달라짐)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Dataset을 정의하고 DataLoader로 전달해보자\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "from torch.utils.data import TensorDataset\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# tensordataset은 기본적으로 텐서를 입력으로 받는다. 데이터를 텐서 형태로 정의하자\r\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \r\n",
    "                               [93,  88,  93], \r\n",
    "                               [89,  91,  90], \r\n",
    "                               [96,  98,  100],   \r\n",
    "                               [73,  66,  70]])  \r\n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\r\n",
    "\r\n",
    "dataset = TensorDataset(x_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# dataset을 dataloader에 전달\r\n",
    "\r\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 모델과 옵티마이즈 설계\r\n",
    "model = nn.Linear(3, 1)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 훈련 진행\r\n",
    "\r\n",
    "nb_epochs = 20\r\n",
    "for epoch in range(nb_epochs + 1):\r\n",
    "    for batch_idx, samples in enumerate(dataloader):\r\n",
    "        # print(batch_idx)\r\n",
    "        # print(samples)\r\n",
    "        x_train, y_train = samples\r\n",
    "\r\n",
    "        # H(x) 계산\r\n",
    "        prediction = model(x_train)\r\n",
    "\r\n",
    "        # cost 계산\r\n",
    "        cost = F.mse_loss(prediction, y_train)\r\n",
    "\r\n",
    "        # cost로 H(x)계산\r\n",
    "        optimizer.zero_grad()\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost {:.6f}'.format(\r\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()\r\n",
    "        ))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost 2.205117\n",
      "Epoch    0/20 Batch 2/3 Cost 1.194232\n",
      "Epoch    0/20 Batch 3/3 Cost 0.022746\n",
      "Epoch    1/20 Batch 1/3 Cost 0.264788\n",
      "Epoch    1/20 Batch 2/3 Cost 2.420995\n",
      "Epoch    1/20 Batch 3/3 Cost 2.922558\n",
      "Epoch    2/20 Batch 1/3 Cost 0.207612\n",
      "Epoch    2/20 Batch 2/3 Cost 0.869992\n",
      "Epoch    2/20 Batch 3/3 Cost 4.846232\n",
      "Epoch    3/20 Batch 1/3 Cost 3.080308\n",
      "Epoch    3/20 Batch 2/3 Cost 0.079927\n",
      "Epoch    3/20 Batch 3/3 Cost 2.839371\n",
      "Epoch    4/20 Batch 1/3 Cost 2.544896\n",
      "Epoch    4/20 Batch 2/3 Cost 1.177169\n",
      "Epoch    4/20 Batch 3/3 Cost 0.326720\n",
      "Epoch    5/20 Batch 1/3 Cost 1.081864\n",
      "Epoch    5/20 Batch 2/3 Cost 2.097448\n",
      "Epoch    5/20 Batch 3/3 Cost 0.193575\n",
      "Epoch    6/20 Batch 1/3 Cost 2.523481\n",
      "Epoch    6/20 Batch 2/3 Cost 0.100339\n",
      "Epoch    6/20 Batch 3/3 Cost 0.920617\n",
      "Epoch    7/20 Batch 1/3 Cost 0.183061\n",
      "Epoch    7/20 Batch 2/3 Cost 2.045108\n",
      "Epoch    7/20 Batch 3/3 Cost 2.487349\n",
      "Epoch    8/20 Batch 1/3 Cost 0.773287\n",
      "Epoch    8/20 Batch 2/3 Cost 3.647747\n",
      "Epoch    8/20 Batch 3/3 Cost 0.205212\n",
      "Epoch    9/20 Batch 1/3 Cost 1.342764\n",
      "Epoch    9/20 Batch 2/3 Cost 2.511305\n",
      "Epoch    9/20 Batch 3/3 Cost 0.016511\n",
      "Epoch   10/20 Batch 1/3 Cost 1.873628\n",
      "Epoch   10/20 Batch 2/3 Cost 2.237000\n",
      "Epoch   10/20 Batch 3/3 Cost 0.432147\n",
      "Epoch   11/20 Batch 1/3 Cost 2.438169\n",
      "Epoch   11/20 Batch 2/3 Cost 0.579089\n",
      "Epoch   11/20 Batch 3/3 Cost 0.079919\n",
      "Epoch   12/20 Batch 1/3 Cost 2.586736\n",
      "Epoch   12/20 Batch 2/3 Cost 0.558503\n",
      "Epoch   12/20 Batch 3/3 Cost 0.227054\n",
      "Epoch   13/20 Batch 1/3 Cost 0.463284\n",
      "Epoch   13/20 Batch 2/3 Cost 1.634099\n",
      "Epoch   13/20 Batch 3/3 Cost 2.882109\n",
      "Epoch   14/20 Batch 1/3 Cost 2.772148\n",
      "Epoch   14/20 Batch 2/3 Cost 0.451773\n",
      "Epoch   14/20 Batch 3/3 Cost 0.281676\n",
      "Epoch   15/20 Batch 1/3 Cost 1.082098\n",
      "Epoch   15/20 Batch 2/3 Cost 0.380945\n",
      "Epoch   15/20 Batch 3/3 Cost 4.135963\n",
      "Epoch   16/20 Batch 1/3 Cost 0.672431\n",
      "Epoch   16/20 Batch 2/3 Cost 1.564543\n",
      "Epoch   16/20 Batch 3/3 Cost 3.244517\n",
      "Epoch   17/20 Batch 1/3 Cost 2.104827\n",
      "Epoch   17/20 Batch 2/3 Cost 0.101522\n",
      "Epoch   17/20 Batch 3/3 Cost 2.234007\n",
      "Epoch   18/20 Batch 1/3 Cost 0.583625\n",
      "Epoch   18/20 Batch 2/3 Cost 2.903016\n",
      "Epoch   18/20 Batch 3/3 Cost 0.127914\n",
      "Epoch   19/20 Batch 1/3 Cost 0.501903\n",
      "Epoch   19/20 Batch 2/3 Cost 2.510308\n",
      "Epoch   19/20 Batch 3/3 Cost 0.178558\n",
      "Epoch   20/20 Batch 1/3 Cost 1.577241\n",
      "Epoch   20/20 Batch 2/3 Cost 1.455066\n",
      "Epoch   20/20 Batch 3/3 Cost 0.836738\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 임의의 값으로 예측값 확인\r\n",
    "new_var = torch.FloatTensor([[73, 80, 75]])\r\n",
    "\r\n",
    "pred_y = model(new_var)\r\n",
    "print('훈련 후 입력이 73, 80, 75일 때의 예측값: ', pred_y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값:  tensor([[151.4028]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
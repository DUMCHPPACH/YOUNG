{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# 도구 임포트\r\n",
    "import torch\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# 임의의 텐서 만들기 (1*1*28*28)\r\n",
    "\r\n",
    "inputs = torch.Tensor(1,1,28,28)\r\n",
    "print('inputs 텐서의 크기: {}'.format(inputs.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "inputs 텐서의 크기: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# 첫번째 합성곱층 선언\r\n",
    "conv1 = nn.Conv2d(in_channels = 1,      # 입력받을 채널\r\n",
    "                  out_channels = 32,    # 내보낼 채널\r\n",
    "                  kernel_size = 3,      # 커널 사이즈(3,3)\r\n",
    "                  padding=1)            # 패딩사이즈(zero padding)\r\n",
    "\r\n",
    "print(conv1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# 두번째 합성곱층 구현\r\n",
    "conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\r\n",
    "print(conv2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# 풀링 선언\r\n",
    "pool = nn.MaxPool2d(2)      # 인자를 하나만 넣으면 kernel, stride로 모두 지정된다.\r\n",
    "print(pool)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# 구현한 것들을 연결하여 모델 만들기\r\n",
    "\r\n",
    "# 첫번째 합성곱을을 통과한 inputs의 변화 보기\r\n",
    "out = conv1(inputs)\r\n",
    "print(out.shape)\r\n",
    "# inputs 텐서의 크기: torch.Size([1, 1, 28, 28])\r\n",
    "# >> torch.Size([1, 32, 28, 28])\r\n",
    "# 32채널 : conv1의 아웃채널을 32로 지정했기때문\r\n",
    "# 28,28 : padding 을 1로 설정하고 kernel size가 3*3이기 때문에 크기가 보존 됨"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# maxpool을 통과한 값도 확인\r\n",
    "# MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\r\n",
    "out = pool(out)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# conv2 를 통과한 사이즈도 확인\r\n",
    "out = conv2(out)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# 다시 pooling 통과한 크기 확인\r\n",
    "out = pool(out)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# 결과로 나온 feature map을 1차원으로 펴주자\r\n",
    "# n번째 차원에 접근하게 해주는 .size(n)를 사용하자\r\n",
    "\r\n",
    "# out의 각 차원이 몇인지 확인\r\n",
    "print(out.size(0))\r\n",
    "print(out.size(1))\r\n",
    "print(out.size(2))\r\n",
    "print(out.size(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "64\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# 이 값을 갖고 .view()를 사용해 텐서를 펼쳐보자  \r\n",
    "\r\n",
    "# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\r\n",
    "out = out.view(out.size(0), -1)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# 펼친 feature map을 fully connected layer에 통과시키자\r\n",
    "\r\n",
    "fc = nn.Linear(3136, 10)\r\n",
    "out = fc(out)\r\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "### 위 방법들을 이용해 CNN으로 MNIST 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# 필요한 도구 임포트\r\n",
    "import torch\r\n",
    "import torchvision.datasets as dsets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn.init"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# 사용할 디바이스 선택\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "# 랜덤 시드 고정\r\n",
    "torch.manual_seed(777)\r\n",
    "\r\n",
    "# gpu 사용 가능일 때에도 cuda.manual_seed_all 지정\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# 학습에 사용할 파라미터 설정\r\n",
    "learning_rate = 0.001\r\n",
    "training_epochs = 15\r\n",
    "batch_size = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# DataLoader에 사용하기 위한 Dataset을 정의\r\n",
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', # 다운받을 경로\r\n",
    "                          train = True, # True를 지정하면 train_data를 다운로드\r\n",
    "                          transform = transforms.ToTensor(), # 텐서로 변환\r\n",
    "                          download=True)\r\n",
    "\r\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/',\r\n",
    "                         train = False,\r\n",
    "                         transform = transforms.ToTensor(),\r\n",
    "                         download = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# DataLoader사용하여 batch_size를 지정\r\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train,\r\n",
    "                                          batch_size = batch_size,\r\n",
    "                                          shuffle = True,\r\n",
    "                                          drop_last = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# 클래스로 모델을 설계\r\n",
    "\r\n",
    "class CNN(torch.nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(CNN, self).__init__()\r\n",
    "\r\n",
    "        # 첫번째 층 || input_image(?, 28, 28, 1) > Conv1 > (?, 28, 28, 32) > pool > (?, 14, 14, 32)\r\n",
    "        self.layer1 = torch.nn.Sequential(\r\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\r\n",
    "            torch.nn.ReLU(),\r\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "        \r\n",
    "        # 두번째 층 || (?, 14, 14, 32) > conv2 > (?, 14, 14, 64) > pool > (?, 7, 7, 64)\r\n",
    "        self.layer2 = torch.nn.Sequential(\r\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\r\n",
    "            torch.nn.ReLU(),\r\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
    "\r\n",
    "        # Fully conected layer || 7*7*64 inputs > 10 outputs\r\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\r\n",
    "\r\n",
    "        # 전결합층을 한정으로 가중치 초기화\r\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = out.view(out.size(0), -1)\r\n",
    "        out = self.fc(out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# CNN 모델 정의\r\n",
    "model = CNN().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# 비용 함수와 옵티마이저 정의\r\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)  # 비용 함수에 sofrmax가 포함\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# 총 배치수 확인\r\n",
    "total_batch = len(data_loader)\r\n",
    "print('총 배치의 수: {}'.format(total_batch))\r\n",
    "\r\n",
    "# 총 배치의 수(600) * 배치 사이즈(100) = 전체 훈련 데이터(60,000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "총 배치의 수: 600\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# training_epochs 만큼 훈련 진행\r\n",
    "\r\n",
    "for epoch in range(training_epochs):\r\n",
    "    avg_cost = 0\r\n",
    "    \r\n",
    "    for X, Y in data_loader:    # 미니 배치 단위로 가져오기. x:데이터, y:레이블\r\n",
    "        # 이미지는 이미 (28*28)이므로 reshape 필요 없음\r\n",
    "        # 라벨은 one-hot encoding 되지 않았음\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        hypothesis = model(X)\r\n",
    "        cost = criterion(hypothesis, Y)\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += cost / total_batch\r\n",
    "    \r\n",
    "    print('[Epoch: {:>4}] cost = {:.9}'.format(epoch + 1, avg_cost))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch:    1] cost = 0.225616753\n",
      "[Epoch:    2] cost = 0.0629506782\n",
      "[Epoch:    3] cost = 0.0463600233\n",
      "[Epoch:    4] cost = 0.0375382006\n",
      "[Epoch:    5] cost = 0.031426914\n",
      "[Epoch:    6] cost = 0.0261538494\n",
      "[Epoch:    7] cost = 0.0220672395\n",
      "[Epoch:    8] cost = 0.0183010641\n",
      "[Epoch:    9] cost = 0.0164200179\n",
      "[Epoch:   10] cost = 0.0135397073\n",
      "[Epoch:   11] cost = 0.0104772886\n",
      "[Epoch:   12] cost = 0.0100616114\n",
      "[Epoch:   13] cost = 0.00816558022\n",
      "[Epoch:   14] cost = 0.00662278617\n",
      "[Epoch:   15] cost = 0.00705707865\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# 테스트를 진행\r\n",
    "\r\n",
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\r\n",
    "with torch.no_grad():\r\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\r\n",
    "    Y_test = mnist_test.test_labels.to(device)\r\n",
    "\r\n",
    "    prediction = model(X_test)\r\n",
    "    correct_predict = torch.argmax(prediction, 1) == Y_test\r\n",
    "    accuracy = correct_predict.float().mean()\r\n",
    "    print('Accuracy: ', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\envs\\chch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\lemon\\anaconda3\\envs\\chch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.9860999584197998\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 03. 토치텍스트 튜토리얼(Torchtext tutorial) - 한국어\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 한국어로 진행해보자"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 훈련 데이터와 테스트 데이터 다운로드\r\n",
    "import urllib.request\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "datapath = 'D:/chch/startwhithtorch/datafolder/'\r\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt', filename = datapath + \"rating_train.txt\")\r\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt', filename = datapath + \"rating_test.txt\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('D:/chch/startwhithtorch/datafolder/rating_test.txt',\n",
       " <http.client.HTTPMessage at 0x176f5663880>)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 다운받은 txt 데이터를 df 형태로 매핑\r\n",
    "train_df = pd.read_table(datapath + \"rating_train.txt\")\r\n",
    "test_df = pd.read_table(datapath + \"rating_test.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 훈련 데이터 확인\r\n",
    "print(train_df.head())\r\n",
    "print(test_df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         id                                           document  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
      "        id                                           document  label\n",
      "0  6270596                                                굳 ㅋ      1\n",
      "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
      "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
      "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 샘플 개수 확인\r\n",
    "print('훈련 데이터 샘플의 개수: {}'.format(len(train_df)))\r\n",
    "print('테스트 데이터 샘플의 개수: {}'.format(len(test_df)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "훈련 데이터 샘플의 개수: 150000\n",
      "테스트 데이터 샘플의 개수: 50000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. 필드 정의하기(torchtext.data)\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from torchtext.legacy import data\r\n",
    "from eunjeon import Mecab\r\n",
    "\r\n",
    "# 토크나이저(토큰화 도구)는 Mecab을 이용\r\n",
    "tokenizer = Mecab()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# 네이버 영화 리뷰 데이터는 3개의 열로 구성되어 있으니 3개의 필드를 정의\r\n",
    "\r\n",
    "# id 필드 정의\r\n",
    "ID = data.Field(sequential=False,  # 시퀀스 아님\r\n",
    "                use_vocab = False) # 단어 집합 만들지 않음\r\n",
    "\r\n",
    "# text data 필드 정의\r\n",
    "TEXT = data.Field(sequential=True,\r\n",
    "                  use_vocab = True,\r\n",
    "                  tokenize = tokenizer.morphs,\r\n",
    "                  lower = True,\r\n",
    "                  batch_first = True,\r\n",
    "                  fix_length = 20)\r\n",
    "\r\n",
    "# label 필드 정의\r\n",
    "LABEL = data.Field(sequential=False,\r\n",
    "                   use_vocab = False,\r\n",
    "                   is_target=True)   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. 데이터셋 만들기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from torchtext.legacy.data import TabularDataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 데이터를 불러와서 데이터셋의 형식으로 바꾸면서 토큰화까지 진행하자\r\n",
    "train_data, test_data = TabularDataset.splits(path=datapath, train = 'rating_train.txt', test = 'rating_test.txt',\r\n",
    "                                              format = 'tsv', \r\n",
    "                                              fields = [('id', ID), ('text', TEXT), ('label', LABEL)], skip_header=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 데이터셋으로 변환된 샘플의 개수 확인\r\n",
    "print('훈련 데이터 샘플의 개수: {}'.format(len(train_data)))\r\n",
    "print('테스트 데이터 샘플의 개수: {}'.format(len(test_data)))\r\n",
    "\r\n",
    "# 앞서 확인한 개수와 동일할 거임"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "훈련 데이터 샘플의 개수: 150000\n",
      "테스트 데이터 샘플의 개수: 50000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 학습데이터의 첫번째 샘플을 출력해보자\r\n",
    "print(vars(train_data[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': '9976970', 'text': ['아', '더빙', '.', '.', '진짜', '짜증', '나', '네요', '목소리'], 'label': '0'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 단어 집합(Vocabulary) 만들기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 정의한 필드에 .build_vocab() 도구를 사용해 단어집합을 생성하자\r\n",
    "TEXT.build_vocab(train_data, min_freq = 10, max_size = 10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 생성된 단어 집합의 크기 확인\r\n",
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "단어 집합의 크기 : 10002\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# .stoi 로 단어 집합 내 단어를 확인\r\n",
    "print(TEXT.vocab.stoi)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. 토치텍스트의 데이터로더 만들기\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Iterator를 사용해 미니배치만큼 데이터를 둘러오는 데이터로더 만들기\r\n",
    "\r\n",
    "from torchtext.legacy.data import Iterator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# 임의 배치 지정\r\n",
    "batch_size = 5\r\n",
    "\r\n",
    "train_loader = Iterator(dataset=train_data, batch_size=batch_size)\r\n",
    "test_loader = Iterator(dataset=test_data, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\r\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "훈련 데이터의 미니 배치 수 : 30000\n",
      "테스트 데이터의 미니 배치 수 : 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 첫번째 미니 배치를 받아 batch에 저장하고 첫번쨰 미니 배치의 test 필드를 호출하자\r\n",
    "batch = next(iter(train_loader))\r\n",
    "print(batch.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1702,    8,   18, 3515,    8,   18,  576,    8, 1733,  108,   36,   15,\n",
      "         1733,  114,   45,   80,   36,   15,   58,  392],\n",
      "        [ 256,    0,  788, 2906,   23, 1119,  992,  116,    6,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 976,   10, 2067, 1473,   60,  251,   91,   96,  118,  304,    6,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   0,    0,  316,  118,  424,    0,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [6579, 1335,    4, 1375,   99,   30,   49,   31,  142,  495,   80,  810,\n",
      "           14,  884,   36, 1843,    1,    1,    1,    1]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# unk 는 0\r\n",
    "# padding 은 1 로 설정된 것을 확인"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
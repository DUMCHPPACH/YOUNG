{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 4강 기본모델 구축 + 저장\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 이미지 처리에 성과가 좋은 CNN 모델을 구현해보자"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 라이브러리 불러오기\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---  \r\n",
    "## Load data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 데이터와 어떻게 불러올지 설정\r\n",
    "\r\n",
    "transform = transforms.Compose(\r\n",
    "    [transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
    "\r\n",
    "trainset = torchvision.datasets.CIFAR10(root='D:/chchdata/dataset', train=True, download=True, transform = transform)\r\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle = True, num_workers=2)\r\n",
    "testset = torchvision.datasets.CIFAR10(root='D:/chchdata/dataset', train = False, download=True, transform=transform)\r\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=True, num_workers=2)\r\n",
    "\r\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer','dog','frog','horse','ship','truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## Build a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "class Net(nn.Module):  # nn.modules 를 상속받음\r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        x = x.view(-1, 16*5*5)  # 사이즈를 변형하는 레이어(1자로 펴는 작업)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "net = Net()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 모델 확인\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## Implement the model with training set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch.optim as optim\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # net.parameters() : 이 부분이 모델의 파라미터를 업데이트한다는 뜻"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 실직적인 학습 부분\r\n",
    "\r\n",
    "for epoch in range(1) :                                                 # epoch 횟수 설정\r\n",
    "\r\n",
    "    running_loss = 0.0\r\n",
    "    for i, data in enumerate(trainloader, 0):                           # 트레인로더에서 트레인 데이터 불러오기\r\n",
    "        # get the inputs; data is a list of [inputs, labels]\r\n",
    "        inputs, labels = data                                           # 데이터 안에는 이미지, 라벨이 있음\r\n",
    "\r\n",
    "        # zero the parameter gradients\r\n",
    "        optimizer.zero_grad()                                           # 옵티마이저 초기화 작업\r\n",
    "\r\n",
    "        # forward + backward + optimizer\r\n",
    "        outputs = net(inputs)                                           # 이미지를 net 모델에 넣기\r\n",
    "        loss = criterion(outputs, labels)                               # outputs과 labels을 비교해서 loss 계산\r\n",
    "        loss.backward()                                                 # loss를 기준으로 gradient를 계산해서 backward를 진행\r\n",
    "        optimizer.step()                                                # 이렇게 한 번 돌면 배치크기 만큼 돌리면서 loss를 누적하게 됨\r\n",
    "\r\n",
    "        # print statistics\r\n",
    "        running_loss += loss.item()\r\n",
    "        if i % 2000 == 1000 :                                           # 설정한 값 마다 loss 출력\r\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\r\n",
    "            running_loss = 0.0\r\n",
    "    \r\n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\envs\\chch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,  1001] loss: 1.129\n",
      "[1,  3001] loss: 1.888\n",
      "[1,  5001] loss: 1.626\n",
      "Finished Training\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---  \r\n",
    "## save the trained model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "PATH = 'D:/chchdata/pth/cifar_net.pth'  # 모델에서 나온 가중치를 저장할 경로 지정\r\n",
    "torch.save(net.state_dict(), PATH)      # model이름.state_dict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## load the pre-trained model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "net = Net()\r\n",
    "net.load_state_dict(torch.load(PATH))\r\n",
    "# 잘 불러와짐"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## test에 적용  \r\n",
    "output은 미니배치의 결과가 산출되기 때문에 for문을 통해서 test 전체의 예측값을 구해야 한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "correct = 0\r\n",
    "total = 0\r\n",
    "with torch.no_grad():   # 업데이트를 안 하는 것으로 설정\r\n",
    "    for data in testloader:\r\n",
    "        images, labels = data\r\n",
    "        outputs = net(images)\r\n",
    "        _, predicted = torch.max(outputs.data, 1)   # == argmax / 10개의 라벨이 1개로 바뀐다\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels).sum().item()\r\n",
    "\r\n",
    "print('1000개의 test 이미지에 대한 모델 가중치 정확도: %d %%'%(100 * correct / total))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000개의 test 이미지에 대한 모델 가중치 정확도: 45 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "gpu로 연산하게 하는 방법은 포함되지 않았음"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "fdd75c4cec139db88207ac7c4293bdcbae3543546183bc362ebf9b62ac7e89fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}